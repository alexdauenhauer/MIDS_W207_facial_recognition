{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W207 Final Project: Facial Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Team: MapReduce, MapReuse, MapRecycle\n",
    "Members: Tennison Yu, Madeleine Bulkow, Mark Paluta, Alex Dauenhauer\n",
    "\n",
    "https://github.com/tyu0912/MIDS_W207_facial_recognition/issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This is the final project submission from Team MapReduce,MapReuse,MapRecycle for W207: Applied Machine Learning as part of the MIDS program at UC Berkeley. We are working with data from https://www.kaggle.com/c/facial-keypoints-detection/data and the goal is to accurately identify facial features on an (x, y) coordinate system based on an input image. \n",
    "\n",
    "## Overall Project Flow\n",
    "\n",
    "Our project is layed out into the following parts:\n",
    "\n",
    "1) EDA - We explore the data and see what the images and labels we are working with are like\n",
    "\n",
    "2) Feature Engineering - We alter/augment images to expand our training set to better cover edge cases and generalize the algorithm. Based on our exploration of common standard techniques done, we decided to flip, contrast, blur, and rotate the images.\n",
    "\n",
    "3) Simple Modeling - We explore the effectiveness of simple algorithms such as Decision Trees and Neast Neighbors and compare and contrast their effectiveness. \n",
    "\n",
    "4) Complex Modeling - We explore the effectiveness of a more complex model, convoluted neural networks (CNN).\n",
    "\n",
    "5) Summary and Apply - We present our findings and apply our best predictive algorithm to the test data that Kaggle provided us to see how well we did. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages, Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:49:08.517980Z",
     "start_time": "2018-12-09T18:49:08.512993Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Optional cell to install/update all required packages\n",
    "# ! pip install keras tensorflow numpy pandas matplotlib scipy imgaug opencv-python pydot graphviz > nul\n",
    "# print('Packages installed, output supressed for cleanliness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:49:15.950126Z",
     "start_time": "2018-12-09T18:49:08.526955Z"
    }
   },
   "outputs": [],
   "source": [
    "import time, sys, os, keras, tensorflow as tf, warnings, imgaug as ia\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, pydot, graphviz\n",
    "from importlib import reload\n",
    "from sklearn.utils import shuffle\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "from scipy import stats\n",
    "from imgaug import augmenters as iaa\n",
    "from datetime import datetime\n",
    "\n",
    "# set tensorflow as keras backend\n",
    "if K.backend() not in [\"tensorflow\", 'plaidml']:\n",
    "    print ('Switching keras backend...')\n",
    "    os.environ['KERAS_BACKEND'] = \"tensorflow\"\n",
    "    reload(K)\n",
    "    \n",
    "print('keras version:', keras.__version__)\n",
    "print('tensorflow version:', tf.__version__)\n",
    "print('pandas version:', pd.__version__)\n",
    "print('numpy version:', np.__version__)\n",
    "\n",
    "# Initiate settings and load the data.\n",
    "np.random.seed(0)\n",
    "pd.options.display.max_columns = 30\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train = pd.read_csv('training.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print ('Everything Loaded Successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by exploring our data. It is important to understand the range of values we can take on, whether there is missing data, and whether there might be erroneous data. We will be exploring primarily on the image level, as opposed to on the individual keypoint or pixel level, because pixels and keypoints tell a much more important story via their relationship to one another rather than in isolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glancing at the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will see the format our data is in. They keypoints are provided in x or y coordinate floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:49:16.010983Z",
     "start_time": "2018-12-09T18:49:15.953118Z"
    }
   },
   "outputs": [],
   "source": [
    "train[train.columns[:-1]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixels are in a greyscale 8-bit format (range 0 to 255)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:49:16.029914Z",
     "start_time": "2018-12-09T18:49:16.013955Z"
    }
   },
   "outputs": [],
   "source": [
    "train['Image'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first interesting observation is that not all of the images contain all keypoints. In fact no keypoint is present in every image and many are present in less than half of the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:49:16.054856Z",
     "start_time": "2018-12-09T18:49:16.032904Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above cells, we can see that we are given x,y coordinates for our different features in seperate columns. As well, images are currently strings with each pixel value separated by a space. We will need to manipulate these to a form we can work with such as numpy arrays.\n",
    "\n",
    "Additionally, many labels have a lot of missing data. The only label that is complete appears to be the nose tip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformating the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems for complex models such as the CNN, keras requires the data to be in numpy array form with dimensions = (batch, image_width, image_height, num_channels). Images in dataset are 96x96 grayscale images, therefore shape should be (X, 96, 96, 1).\n",
    "\n",
    "To ensure we have data to work stored away for development, we will also split the training set into 80% train data and 20% dev data in the steps below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:49:16.070806Z",
     "start_time": "2018-12-09T18:49:16.058835Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def process_datasets(df, test=False, fillna=False, dropna=False):\n",
    "    '''This function reformats the data from a dataframe to a numpy\n",
    "    array of the appropriate shape.\n",
    "    '''\n",
    "\n",
    "    # whether or not to remove images with missing labels\n",
    "    if dropna:\n",
    "        df = df.dropna()\n",
    "    \n",
    "    # build feature dict for reference in future functions\n",
    "    feature_dict = {label:i for i,label in enumerate(df.columns[:-1].values)}\n",
    "    \n",
    "    # separate images into numpy arrays\n",
    "    images_pixel_feature = df.Image.apply(lambda im: np.fromstring(im, sep=' '))\n",
    "    \n",
    "    # rescale pixel values to [0,1] interval and reshape\n",
    "    images_pixel_feature = np.stack(images_pixel_feature) / 255\n",
    "    images_pixel_feature = images_pixel_feature.reshape(-1, 96, 96, 1)\n",
    "    \n",
    "    \n",
    "    # separate the labels and scale them to [-1,1] interval for use of \n",
    "    # rectified linear unit activation\n",
    "    if not test:\n",
    "        facial_point_labels = df.iloc[:, :-1]\n",
    "        if fillna:\n",
    "            facial_point_labels.fillna(np.mean(facial_point_labels, axis=0), inplace=True)\n",
    "        facial_point_labels = facial_point_labels.values\n",
    "        facial_point_labels = (facial_point_labels - 48) / 48\n",
    "    else:\n",
    "        facial_point_labels = None\n",
    "    \n",
    "    return images_pixel_feature, facial_point_labels, feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:49:39.706696Z",
     "start_time": "2018-12-09T18:49:16.073794Z"
    }
   },
   "outputs": [],
   "source": [
    "# Raw data\n",
    "# train_raw = processed but not split\n",
    "train_data_raw, train_labels_raw, feature_dict = process_datasets(train)\n",
    "test_data, test_labels, _ = process_datasets(test, test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Random Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we wanted to observe some sample images with labels to see what kind of variety of images we are working with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:49:39.718632Z",
     "start_time": "2018-12-09T18:49:39.708658Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_sample(data, labels, labels2=None):\n",
    "    '''\n",
    "    data must be a numpy.ndarray of shape (X, 96, 96, 1)\n",
    "    labels must be a numpy.ndarray (X, 30)\n",
    "    X must be any square number\n",
    "    labels = true labels\n",
    "    labesl2 = predicted labels (optional)\n",
    "    '''\n",
    "    \n",
    "    dim = np.sqrt(len(data))\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "    for i in range(len(labels)):\n",
    "        img = data[i].reshape(96,96)\n",
    "        ax = fig.add_subplot(dim, dim, i + 1, xticks=[], yticks=[])\n",
    "        ax.imshow(data[i].reshape(96,96), cmap='gray')\n",
    "        ax.scatter(labels[i][0::2] * 48 + 48, labels[i][1::2] * 48 + 48, c='r')\n",
    "        if not labels2 is None:\n",
    "            ax.scatter(labels2[i][0::2] * 48 + 48, labels2[i][1::2] * 48 + 48, c='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:49:40.767829Z",
     "start_time": "2018-12-09T18:49:39.723620Z"
    }
   },
   "outputs": [],
   "source": [
    "# Output sample of random images. Some of these will be the NA data\n",
    "n = 25\n",
    "idx = np.random.randint(0, len(train_data_raw), n)\n",
    "data_sample = train_data_raw[idx, :, :, :]\n",
    "label_sample = train_labels_raw[idx, :]\n",
    "plot_sample(data_sample, label_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, there is great diversity in the images that we are working with. Not all are frontal shots as some of the heads are angled and tilted. Some of the images are also more blured/sharp, some are darker/lighter and some are wearing glasses. We can also confirm from above that many images do not possess a complete set of labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Edge Cases\n",
    "\n",
    "In addition to random faces, we wondered what some edge cases are like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:49:40.784784Z",
     "start_time": "2018-12-09T18:49:40.769823Z"
    }
   },
   "outputs": [],
   "source": [
    "edge_cases = []\n",
    "\n",
    "# compile interesting cases\n",
    "edge_cases.extend(train_labels_raw[:,feature_dict['nose_tip_x']].argsort()[:10])           # noses near left of screen\n",
    "edge_cases.extend(train_labels_raw[:,feature_dict['nose_tip_x']].argsort()[-10:])          # noses near right of screen\n",
    "edge_cases.extend(train_labels_raw[:,feature_dict['nose_tip_y']].argsort()[:10])           # noses near top of screen\n",
    "edge_cases.extend((train_labels_raw[:,feature_dict['right_eye_center_x']] -\n",
    "                   train_labels_raw[:,feature_dict['left_eye_center_x']]).argsort()[:10])  # wide faces\n",
    "edge_cases.extend((train_labels_raw[:,feature_dict['right_eye_center_x']] -\n",
    "                   train_labels_raw[:,feature_dict['left_eye_center_x']]).argsort()[-9:]) # small faces\n",
    "\n",
    "print(len(edge_cases), edge_cases)\n",
    "\n",
    "data_edge = train_data_raw[edge_cases, :, :, :]\n",
    "label_edge = train_labels_raw[edge_cases, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:49:42.781448Z",
     "start_time": "2018-12-09T18:49:40.787777Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_sample(data_edge, label_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, it looks like there are several different types of edge cases. Some images have features obscured (hair over eyes, sunglasses, etc) and therefore are missing labels. Some cases look like purely bad data that may need to be removed such as the first picture of Leonardo DiCarpio and image 18, where it is a not a face but a collection of pictures. Also interesting is that there are images that are very similar. For instance, image 28, 29, 30 all seem to be the same woman but in image 28 her mouth is closed, and image 29 is a little darker than image 30. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing erroneous data  \n",
    "To remove the data considered bad data, we utilized a method that will be covered in our appendix to flag likely erroneous images. They are printed here to confirm that they indeed look erroneous, and then we throw them out for the remainder of our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:50:12.136110Z",
     "start_time": "2018-12-09T18:50:09.415381Z"
    }
   },
   "outputs": [],
   "source": [
    "# hard code in flagged images\n",
    "flagged = [1230, 1620, 1649, 1652, 1723, 1747, 1808, 1834, 1861, 1877, 1881, 1907, 1927, 1942, 1966, 1995,\n",
    "           2036, 2096, 2175, 2191, 2199, 2244, 2289, 2453, 2484, 2533, 2562, 2629, 2664, 2700, 2787, 2818,\n",
    "           2831, 2845, 2982, 3087, 3173, 3296, 3307, 3374, 3447, 3487, 3510, 3647, 3888, 4180, 4263, 4480,\n",
    "           4482, 4490, 4601, 4717, 4786, 5117, 5795, 5952, 6082, 6271, 6315, 6405, 6407, 6492, 6493, 6569,\n",
    "           6585, 6765, 6782, 6834, 6906]\n",
    "\n",
    "# plot these images as a sanity check that they are in fact \"bad\" data\n",
    "i = 0\n",
    "rows = 8\n",
    "cols = len(flagged)//rows + 1\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "for index in flagged:\n",
    "    ax = fig.add_subplot(rows, cols, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(train_data_raw[index].reshape(96,96), cmap='gray')\n",
    "    ax.scatter(train_labels_raw[index][0::2] * 48 + 48, train_labels_raw[i][1::2] * 48 + 48, c='r')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:50:20.665431Z",
     "start_time": "2018-12-09T18:50:20.313341Z"
    }
   },
   "outputs": [],
   "source": [
    "# Delete these images from the data set forever\n",
    "train_data_raw = np.delete(train_data_raw, flagged, 0)\n",
    "train_labels_raw = np.delete(train_labels_raw, flagged, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there are so many images with incomplete values, we now need to define another set with NA removed that will be used later on to train simple baseline models as well as predict the position of the missing labels for later training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:50:57.484047Z",
     "start_time": "2018-12-09T18:50:51.831148Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping NAs\n",
    "# drop bad data from original dataframe\n",
    "train = train.drop(flagged)\n",
    "\n",
    "# train_complete = no missing values\n",
    "train_data_complete, train_labels_complete, _ = process_datasets(train, dropna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:50:59.471018Z",
     "start_time": "2018-12-09T18:50:59.087045Z"
    }
   },
   "outputs": [],
   "source": [
    "### DON'T RUN THIS CELL MORE THAN ONCE WITHOUT RE-RUNNING PROCESS DATASETS! ###\n",
    "\n",
    "# 20% of the data will go to dev\n",
    "percent_to_dev = 0.2 \n",
    "\n",
    "# Note the naming convention change.\n",
    "# train_orig = with missing values\n",
    "\n",
    "train_data_orig, dev_data_orig, train_labels_orig, dev_labels_orig = train_test_split(\n",
    "    train_data_raw, train_labels_raw, test_size=percent_to_dev\n",
    ")\n",
    "train_data_complete, dev_data_complete, train_labels_complete, dev_labels_complete = train_test_split(\n",
    "    train_data_complete, train_labels_complete, test_size=percent_to_dev\n",
    ")\n",
    "\n",
    "print(\"\\nTrain data shape\", train_data_orig.shape)\n",
    "print(\"Dev data shape\", dev_data_orig.shape)\n",
    "print(\"Train labels shape\", train_labels_orig.shape)\n",
    "print(\"Dev labels shape\", dev_labels_orig.shape)\n",
    "print(\"\\nTrain data no-missing-values shape\", train_data_complete.shape)\n",
    "print(\"Dev data no-missing-values shape\", dev_data_complete.shape)\n",
    "print(\"Train labels no-missing-values shape\", train_labels_complete.shape)\n",
    "print(\"Dev labels no-missing-values shape\", dev_labels_complete.shape)\n",
    "\n",
    "print(\"\\nData Generation Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be sure we can capture some of these edge cases, we expand the variety of our data set even more. We decided to create sets of images that were mirrored, contrasted, blurred, and rotated as it seems these are the most prevalent gestures of the different faces. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:51:07.237548Z",
     "start_time": "2018-12-09T18:51:07.223582Z"
    },
    "code_folding": [
     2,
     37
    ]
   },
   "outputs": [],
   "source": [
    "# We use the imgaug library to generate our new sets of images\n",
    "\n",
    "def augment_images(data, labels, aug):\n",
    "    \n",
    "    data = data * 255\n",
    "    aug_labels =[]\n",
    "    seq_det = aug.to_deterministic()\n",
    "    aug_data = seq_det.augment_images(data)\n",
    "    \n",
    "    keypoints_on_images = []\n",
    "    \n",
    "    for features in labels:\n",
    "        keypoints = []\n",
    "        \n",
    "        for c in range(0, features.shape[0], 2):\n",
    "            x = features[c]* 48 + 48\n",
    "            y = features[c+1]* 48 + 48\n",
    "\n",
    "            keypoints.append(ia.Keypoint(x=x, y=y))\n",
    "\n",
    "        keypoints_on_images.append(ia.KeypointsOnImage(keypoints, shape=(96,96)))\n",
    "    \n",
    "    keypoints_aug = seq_det.augment_keypoints(keypoints_on_images)    \n",
    "        \n",
    "    for keypoints_after in keypoints_aug:\n",
    "        aug_labels_set = []\n",
    "        \n",
    "        for i, keypoint in enumerate(keypoints_after.keypoints):\n",
    "            aug_labels_set.append((keypoint.x - 48) / 48)\n",
    "            aug_labels_set.append((keypoint.y - 48) / 48)\n",
    "                \n",
    "        aug_labels.append(aug_labels_set)\n",
    "        \n",
    "    return aug_data/255, np.array(aug_labels)\n",
    "\n",
    "# The imgaug library confuses the labels in the case of mirroring an image so we made our own custom method. \n",
    "\n",
    "def mirror_data(data, labels, features):\n",
    "    '''This function flips the images and labels to their new columns\n",
    "    Input data is numpy array of shape (X, 96, 96, 1)\n",
    "    Input labels is numpy array of shape (X, 30)\n",
    "    features is a list of column header strings\n",
    "    '''\n",
    "    \n",
    "    # flip the images\n",
    "    data_flipped = data[:, :, ::-1, :]\n",
    "    \n",
    "    # flip the labels\n",
    "    labels_flipped = np.zeros(labels.shape)\n",
    "    for idx in range(len(labels)):\n",
    "        for i,s1 in enumerate(features):\n",
    "            parts = s1.partition('_')\n",
    "            if parts[0] == 'left' or parts[0] == 'right':\n",
    "                coord = parts[-1]\n",
    "            elif parts[0] == 'mouth':\n",
    "                parts = s1.split('_', maxsplit=2)\n",
    "                if 'corner' in parts[-1]:\n",
    "                    coord = parts[-1]        \n",
    "                elif 'x' in parts[-1]:\n",
    "                    labels_flipped[idx,i] = labels[idx,i] * -1\n",
    "                else:\n",
    "                    labels_flipped[idx,i] = labels[idx,i]\n",
    "            else:\n",
    "                if 'x' in parts[-1]:\n",
    "                    labels_flipped[idx,i] = labels[idx,i] * -1\n",
    "                else:\n",
    "                    labels_flipped[idx,i] = labels[idx,i]\n",
    "            for j in range(i+1,len(features)-1):\n",
    "                s2 = features[j]\n",
    "                if coord in s2:\n",
    "                    if 'x' in coord:\n",
    "                        labels_flipped[idx,i] = labels[idx,j] * -1\n",
    "                        labels_flipped[idx,j] = labels[idx,i] * -1\n",
    "                    else:\n",
    "                        labels_flipped[idx,i] = labels[idx,j]\n",
    "                        labels_flipped[idx,j] = labels[idx,i]\n",
    "                \n",
    "    return data_flipped, labels_flipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:51:14.870386Z",
     "start_time": "2018-12-09T18:51:13.759162Z"
    }
   },
   "outputs": [],
   "source": [
    "# mirror training and dev data\n",
    "flipped_data, flipped_labels = mirror_data(\n",
    "    train_data_orig, train_labels_orig, list(feature_dict.keys())\n",
    ")\n",
    "\n",
    "flipped_data_complete, flipped_labels_complete = mirror_data(\n",
    "    train_data_complete, train_labels_complete, list(feature_dict.keys())\n",
    ")\n",
    "\n",
    "# Concatanating to make new set\n",
    "\n",
    "# Note the new naming convention\n",
    "# train_aug = augmented with missing values  \n",
    "# train_aug_comp = augmented no missing values\n",
    "\n",
    "train_data_aug = np.concatenate((train_data_orig,flipped_data), axis=0)\n",
    "train_labels_aug =  np.concatenate((train_labels_orig, flipped_labels), axis=0)\n",
    "\n",
    "train_data_aug_comp = np.concatenate((train_data_complete, flipped_data_complete),axis=0)\n",
    "train_labels_aug_comp = np.concatenate((train_labels_complete,flipped_labels_complete),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:51:45.269818Z",
     "start_time": "2018-12-09T18:51:17.396251Z"
    }
   },
   "outputs": [],
   "source": [
    "# We apply 1,2 or 3 of blurring, contrast, and rotation to 50% of the data. \n",
    "# We do this randomly to make sure everything is equally distributed.\n",
    "\n",
    "aug = iaa.Sometimes(0.5,  iaa.SomeOf((1, 3), \n",
    "            [iaa.GammaContrast((0.25, 3)),\n",
    "             iaa.GaussianBlur(sigma=1),\n",
    "             iaa.Affine(rotate=(-10,10), scale={\"x\": (1.05, 1.2), \"y\": (1.05, 1.2)})\n",
    "            ]                        \n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "train_data_aug, train_labels_aug = augment_images(train_data_aug, train_labels_aug, aug)\n",
    "train_data_aug_comp, train_labels_aug_comp = augment_images(train_data_aug_comp, train_labels_aug_comp, aug)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Sample Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:51:45.290731Z",
     "start_time": "2018-12-09T18:51:45.278764Z"
    }
   },
   "outputs": [],
   "source": [
    "img1 = train_data_orig[0].reshape(96,96)\n",
    "lab1 = train_labels_orig[0]\n",
    "img2 = train_data_aug[0].reshape(96,96)\n",
    "lab2 = train_labels_aug[0]\n",
    "img3 = train_data_orig[1].reshape(96,96)\n",
    "lab3 = train_labels_orig[1]\n",
    "img4 = train_data_aug[1].reshape(96,96)\n",
    "lab4 = train_labels_aug[1]\n",
    "img5 = train_data_orig[2].reshape(96,96)\n",
    "lab5 = train_labels_orig[2]\n",
    "img6 = train_data_aug[2].reshape(96,96)\n",
    "lab6 = train_labels_aug[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T18:51:45.894418Z",
     "start_time": "2018-12-09T18:51:45.294722Z"
    }
   },
   "outputs": [],
   "source": [
    "imgs = [img1, img2, img3, img4, img5, img6]\n",
    "labs = [lab1, lab2, lab3, lab4, lab5, lab6]\n",
    "titles = ['original 1','augmented 1','original 2','augmented 2','original 3', 'augmented 3']\n",
    "\n",
    "fig, axes = plt.subplots(1,6,figsize=(20,10))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "for i in range(6):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(imgs[i], cmap='gray')\n",
    "    ax.scatter(labs[i][0::2] * 48 + 48, labs[i][1::2] * 48 + 48, c='r')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(titles[i], fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the augmentations worked. Note again that the augmentations are applied to only 50% of the data so there may be some images above that are not augmented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin our modeling, we select common supervised-learning regression algorithms such as linear regression, k-nearest neighbors, and decision trees/random forests. The thought process behind choosing each one is described below. However, given existing literature, it seems CNN is the preferred way to solve problems of this nature. Therefore greater emphasis will be given for that technique. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiate a dictionary to keep results in\n",
    "result_dict = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As a simple test, we want to look at the average of all the features and what the error of that would be. \n",
    "# We use the complete set to avoid issues with incomplete values. \n",
    "\n",
    "avg_position = np.mean(train_labels_aug_comp, axis=0)\n",
    "predictions = np.ones(train_labels_aug_comp.shape) * avg_position\n",
    "mse = np.sqrt(mean_squared_error(train_labels_aug_comp, predictions)) * 48\n",
    "result_dict['Training Average'] = [None, None, None, predictions]\n",
    "\n",
    "print ('The RMSE error when averaging all the features is', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add in training loss, (predict on self), capture runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More simple baselines\n",
    "regressors = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'DecisionTree': DecisionTreeRegressor(),\n",
    "    'RandomForest': RandomForestRegressor(),\n",
    "    'NearestNeighbors': KNeighborsRegressor()\n",
    "} \n",
    "\n",
    "parameters = {\n",
    "    'RandomForest': {'n_estimators': [6,8,10,12], 'min_samples_split': [3,5,7]}, \n",
    "    'DecisionTree': {'min_samples_split': [3,5,7]},\n",
    "    'NearestNeighbors':  {'n_neighbors': [3,5,7], 'weights': ['uniform','distance'], 'metric': ['euclidean','manhattan','minkowski']}, \n",
    "    'LinearRegression': {'fit_intercept': [True, False], 'normalize':[True, False]}\n",
    "}\n",
    "\n",
    "rmse_scorer = make_scorer(mean_squared_error)\n",
    "\n",
    "def model_training(model, parameters, train_data, labels, dev_data, dev_labels, grid = False):\n",
    "    X = train_data.reshape(-1, 96**2)\n",
    "    Y = labels\n",
    "    \n",
    "    if grid == True:        \n",
    "        grid_obj = GridSearchCV(model, parameters, scoring=rmse_scorer)\n",
    "        grid_obj = grid_obj.fit(X, Y)\n",
    "        \n",
    "        print(grid_obj.best_params_)\n",
    "        \n",
    "        regressor = grid_obj.best_estimator_\n",
    "        start=datetime.now()\n",
    "        regressor.fit(X, Y)\n",
    "        runtime = datetime.now() - start\n",
    "        predictions = regressor.predict(X)\n",
    "        \n",
    "        train_mse = np.sqrt(mean_squared_error(Y, predictions)) * 48\n",
    "\n",
    "        Z = dev_data.reshape(-1, 96**2)\n",
    "\n",
    "        predictions = regressor.predict(Z)\n",
    "        dev_mse = np.sqrt(mean_squared_error(dev_labels, predictions)) * 48\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        start=datetime.now()\n",
    "        model.fit(X,Y)\n",
    "        runtime = datetime.now() - start\n",
    "\n",
    "        predictions = model.predict(X)\n",
    "        train_mse = np.sqrt(mean_squared_error(Y, predictions)) * 48\n",
    "\n",
    "        Z = dev_data.reshape(-1, 96**2)\n",
    "\n",
    "        predictions = model.predict(Z)\n",
    "        dev_mse = np.sqrt(mean_squared_error(dev_labels, predictions)) * 48\n",
    "    \n",
    "    return [train_mse, dev_mse, runtime, predictions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_basic_models(which_set, train_data, train_labels, dev_data, dev_labels, grid = False):\n",
    "    if which_set == 'complete':\n",
    "        print ('This is with the complete set')\n",
    "    elif which_set == 'complete_aug':\n",
    "        print ('This is with the complete_aug set')\n",
    "    \n",
    "    for k,v in regressors.items():\n",
    "        p = parameters[k]\n",
    "        result = model_training(v, p, train_data, train_labels, dev_data, dev_labels, grid)\n",
    "\n",
    "        result_dict[k] = result\n",
    "        print('\\n', k,':\\n',\n",
    "              'Training RMSE=', round(result[0],2),\n",
    "              'Dev RMSE=', round(result[1],2),\n",
    "              'Train Time=', round(result[2].seconds,2)\n",
    "             )\n",
    "\n",
    "    img_idx = 2\n",
    "    img = train_data_complete[img_idx].reshape(96,96)\n",
    "\n",
    "    fig, axes = plt.subplots(1,len(result_dict),figsize=(15,15))\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    for i,(k,v) in enumerate(result_dict.items()):\n",
    "        ax = axes[i]\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.scatter(train_labels_complete[img_idx][0::2] * 48 + 48, train_labels_complete[img_idx][1::2] * 48 + 48, c='r')\n",
    "        ax.scatter(v[3][img_idx][0::2] * 48 + 48, v[3][img_idx][1::2] * 48 + 48, c='b')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(k, fontsize=15)\n",
    "    \n",
    "train_basic_models('complete', train_data_complete, train_labels_complete, dev_data_complete, dev_labels_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_basic_models('complete_aug', train_data_aug_comp, train_labels_aug_comp, dev_data_complete, dev_labels_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "**Rational:** Linear regression essentially minimizes the squared error distance between actual and predicted values. This was picked because of its simplicity and it would be interesting to gauge the performance of a classical regressor.\n",
    "\n",
    "**Weakness:** With a smaller training set size, the RMSE is comparable to that of the other algorithms however once the training set increases, the RMSE gets much worse. This likely means that the algorithm performs poorly with extreme variation in the labels and the images they map to. This is not unexpected as linear models assume a linear relationship between independent variables and the dependent variables. This would not apply to facial positions especially if they are not all full frontal shots. Therefore, it is likely not reliable as an algorithm moving forward.\n",
    "\n",
    "**Future:** There are other linear modeling techniques such as Lasso and ElasticNet which add regularization terms that often are used to reduce overfitting. The results would be interesting to see however the assumption of a linear relationship still applies. Also the choosing of the regularization parameter would warrant some deep investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest/Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rational:** A decision tree is a non-parametric supervised learning method that predicts the value of a target variable by establishing decision rules inferred from the data features. Random forests are just a set of decision trees results where a consensus value has been established either by voting or averaging. We ran a random forest as well because of the weaknesses as described below. \n",
    "\n",
    "**Weakness:** By itself, this decision tree algorithm seemed to perform the worst after linear regression. It could be that we have overfitted the model since decisions can be very complex and is very sensitive to small variations. Tree are also known to ignore the correlation between features, which is highly the case in this experiment. For instance, knowing the position of one eye can often tell you the position of the other eye.\n",
    "\n",
    "**Future:** Hyperparameter tuning to improve performance include pruning, setting the minimum number of samples required at a leaf node or setting the maximum depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rational:** We pick kNN because all facial features are on the same location on the face i.e left eye is on the upper left, right eye is on the upper right, nose is in the middle, etc. Because kNN work by assigning a query point as those of its neighbors, given a set of images, kNN should be able to figure out which pixels is generally associated with the eye area, the nose area, etc.\n",
    "\n",
    "**Weakness:** One potential weakness of this algorithm may be images where the face located off center. For example, if an image has a face translated to the right, then it may mistake the left eye on the image for a right eye\n",
    "\n",
    "**Future:** One of the corner stones of knn is the idea of distance and how that is defined. We use the default Minknowski distance set by sklearn however the use of correlation might be more appropriate since as described above, the position of features on a face are all correlated in some sense. In other studies, Chi square distance also seems to perform well. Both of these would be worth engineering and exploring in the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameter and Hyper-parameter selection:**\n",
    "\n",
    "The Convolutional Neural Network (CNN) has many parameters to choose to build the model. We first need to determine how many layer stacks the model should have. Each layer stack should contain, at a minimum, a convolutional layer and a pooling layer. You can also choose to add a dropout layer at each stack, to help avoid overfitting on the training set.  For each convolutional layer, we need to determine the shape of the convolutional kernel, as well the shape of the pooling kernel. After the convolutional layer stack, the output needs to be flattened and we need to determine the number of dense layers to send it through before generating the output. Again we can choose to add dropout layers here or not. After we have decided on the shape our network will take, we need to determine the optimizer to use, and the loss function. The optimizer comes with its own set of hyperparameters, the most important of which is the initial learning rate according to Bengio.\n",
    "\n",
    "**Optimizer:**  \n",
    "Per Bengio, for stochastic gradient descent (SGD) optimization, \"The optimal learning rate is usually close to the largest learning rate that does not cause divergence of the training criterion.\" His suggestion is to start with a large learning rate and if the training criterion diverges, decrease the learning rate by a factor of 3. Due to hardware memory limitations, we were unable to carry out full hyperparameter tuning via grid search. So rather than search for the optimal SGD learning rate, we chose to use an adaptive optimizer called Adam which converges much faster than standard SGD. Adam is an adaptation/enhancement to SGD. Whereas SGD uses a single learning rate for all weight updates and does not update the learning rate during training, the Adam optimizer \"calculates an exponential moving average of the gradient and the squared gradient.\" The hyperparameters beta1 and beta2 control the decay rates of these moving averages. Because the authors of the Adam optimizer performed hyperparameter tuning on a similar convolutional neural net built for prediction on the MNIST data set, we used the default values of the Adam optimizer which are currently set to the optimal values determined by the authors.\n",
    "\n",
    "**Number of Layers:**  \n",
    "Again according to Bengio, \"the optimal number layers can be determine by simply adding layers until the error does not improve anymore.\" As we were using the Daniel Nouri tutorial as a guide to building the CNN, we started with three convolutional/pooling layer pairs in our CNN. We tested 4 and 5 layer pairs as well which gave little to no improvement in the loss on the validation data, but did increase the training time significantly, so we decided on three layer pairs for the default value of the model. \n",
    "\n",
    "**Number of filters:**\n",
    "Each filter in a convolutional layer can be thought of as a single feature detector. In the initial layer, the filters will be able to detect simple geometric patterns such as a lines or curves. As we go deeper in the network, the feature detectors can become more sophisticated. Since we want to predict the position of 15 facial keypoints varying in shape and size and orientation, we need to have enough feature detectors by the last layer to handle a large variety of features. We tried various combinations of factors of 2 for the number of filters in each layer, with the number of filters multiplying by 2 at each layer. After some trial and error, we settled on 32, 64, 128 filters for convolutional layers 1, 2, and 3 respectively. \n",
    "\n",
    "**Pooling layers:**  \n",
    "The pooling layers determine the factor by which you downscale your data after each convolutional layer. We chose to simply use pooling kernels of (2,2) with a stride of (2,2) so that our output shape at each layer was easy to keep track of\n",
    "\n",
    "**Number of Dense layers and Dense layer nodes:**  \n",
    "Admittedly, we spent more of our time tuning the parameters in the convolutional stack than in the dense layer section of the model, but we did test some variations ranging from 1 layer with 100 nodes to 3 layers of 2000 nodes and ended up settling on 2 layers with 1000 nodes each for our default model values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build a custom loss function to handle NA values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a time callback to track total runtime\n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a custom loss function to handle NAs\n",
    "def mean_squared_error_with_missing(y_true, y_pred):\n",
    "    \n",
    "    # figure out which labels are present\n",
    "    present = tf.logical_not(tf.is_nan(y_true))\n",
    "    \n",
    "    # select only those labels\n",
    "    present_labels_true = tf.boolean_mask(y_true, present)\n",
    "    present_labels_pred = tf.boolean_mask(y_pred, present)\n",
    "    \n",
    "    # compute mean squared error\n",
    "    loss = tf.math.reduce_mean(tf.math.squared_difference(present_labels_true,present_labels_pred))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How we built the model:  \n",
    "We had to decide on the default hyperparameters for our CNN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     11
    ]
   },
   "outputs": [],
   "source": [
    "def build_CNN(\n",
    "    num_ConvLayers=3, \n",
    "    num_DenseLayers=2,\n",
    "    filters=[32,64,128],\n",
    "    kernels=[(3,3),(3,3),(3,3)], \n",
    "    pools=[(2,2),(2,2),(2,2)], \n",
    "    dense_nodes=[1000,1000], \n",
    "    optimizer='Adam', \n",
    "    dropout=None,\n",
    "    input_shape=(96,96,1),\n",
    "    loss=mean_squared_error_with_missing\n",
    "):\n",
    "    '''This function builds a CNN model\n",
    "    num_ConvLayers --> is the number of convolutional layer groups where \n",
    "    each group contains a convolutional layer, a pooling layer, and an\n",
    "    optional dropout layer\n",
    "    \n",
    "    num_DenseLayers --> is the number of dense layers after flattening\n",
    "    the convolutional output\n",
    "    \n",
    "    filters --> a list of the number of filters used in each\n",
    "    convolutional layer specified in num_ConvLayers\n",
    "    \n",
    "    kernels --> a list of the kernel size to use in each convolutional\n",
    "    layer specified in num_ConvLayers\n",
    "    \n",
    "    pools --> a list of the kernel size to use in each pooling layer\n",
    "    specified in num_ConvLayers\n",
    "    \n",
    "    dense_nodes --> a list of the number of units in each dense layer\n",
    "    specified in num_DenseLayers\n",
    "    \n",
    "    dropout --> optional, a list of the dropout rates at each \n",
    "    convolutional layer\n",
    "    \n",
    "    input_shape --> the shape of the input data\n",
    "    '''\n",
    "    # define a Sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # add convolutional layer groups\n",
    "    for i in range(num_ConvLayers):\n",
    "        model.add(Conv2D(\n",
    "            filters=filters[i],\n",
    "            kernel_size=kernels[i],\n",
    "            strides=(1,1),\n",
    "            padding='same',\n",
    "            activation='relu',\n",
    "            input_shape=input_shape\n",
    "        ))\n",
    "        model.add(MaxPooling2D(\n",
    "            pool_size=pools[i],\n",
    "            strides=None\n",
    "        ))\n",
    "        \n",
    "        # add dropout layers if specified\n",
    "        if dropout:\n",
    "            model.add(Dropout(rate=dropout[i]))\n",
    "    \n",
    "    # flatten the convolutional layers\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # add the dense layers\n",
    "    for j in range(num_DenseLayers):\n",
    "        model.add(Dense(\n",
    "            units=dense_nodes[j],\n",
    "            activation='relu'\n",
    "        ))\n",
    "        \n",
    "    # create the output layer\n",
    "    model.add(Dense(units=30))\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     7
    ]
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, \n",
    "    train_data, train_labels, \n",
    "    dev_data=None, dev_labels=None,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    epochs=10\n",
    "):\n",
    "    time_callback = TimeHistory()\n",
    "    hist = keras.callbacks.History()\n",
    "    if not dev_data is None:\n",
    "        model.fit(\n",
    "            train_data, train_labels, \n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs, \n",
    "            validation_data=(dev_data, dev_labels),\n",
    "            verbose=verbose,\n",
    "            callbacks=[hist, time_callback]\n",
    "        )\n",
    "    else:\n",
    "        model.fit(\n",
    "            train_data, train_labels, \n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs, \n",
    "            validation_split=0.2,\n",
    "            verbose=verbose,\n",
    "            callbacks=[hist, time_callback]\n",
    "        )\n",
    "    print('\\nRMS error on validation set:', np.sqrt(hist.history['val_loss'][-1]) * 48)\n",
    "    print('Total runtime (minutes):', round(np.sum(time_callback.times) / 60, 2))\n",
    "    \n",
    "    return hist, time_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualize the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_NN(model):\n",
    "    plot_model(model, to_file='model.png', show_shapes=True)\n",
    "    mod = plt.imread('model.png')\n",
    "    fig = plt.figure(figsize=(10,20), frameon=False)\n",
    "    plt.imshow(mod)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaggle Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def predict_for_kaggle(model, test_data, filename):\n",
    "    \n",
    "    #Predict values for your chosen model\n",
    "    pred = model3.predict(test_data)\n",
    "    \n",
    "    # Get the list of required test points\n",
    "    lookup = pd.read_csv('IdLookupTable.csv')\n",
    "    \n",
    "    #Match up the test points with the predicted values\n",
    "    labelNums = {}\n",
    "    for index, label in enumerate(train.columns.values):\n",
    "        labelNums[label] = index\n",
    "    lookup['FeatureNum'] = lookup.apply(\n",
    "        lambda row: labelNums[row['FeatureName']], axis=1\n",
    "    )\n",
    "    lookup.Location =  np.minimum(\n",
    "        96, np.maximum(0, pred[lookup.ImageId-1, lookup.FeatureNum]*48 + 48)\n",
    "    )\n",
    "    \n",
    "    # save the rowid and the associated location to a csv\n",
    "    lookup.to_csv(\n",
    "        path_or_buf=filename, columns=['RowId','Location'], index=False\n",
    "    )\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To submit, run:\n",
    "kaggle competitions submit -c facial-keypoints-detection -f submission.csv -m \"Message\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Running CNN\n",
    "the below table contains a layout of our training plan. The first model will be trained on the original dataset with missing values and no augmentations applied. The second model will use the original dataset with all augmentations applied. The third model will use the augmented data with NAs filled by 2-layer NN predictions. The fourth model will be the same as model 3 but we will utilize dropout layers to prevent overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table> \n",
    "<tr>\n",
    "<th> Model Name </th> <th> Model Parameters </th> <th> Data </th> <th> Training Criteria </th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td> Model 1 </td> <td> Default </td> <td> Original Data </td> <td> 50 epochs </td>\n",
    "</tr>\n",
    "    <tr>\n",
    "<td> Model 2 </td> <td> Default </td> <td> Original Data + Augmentations </td> <td> 50 epochs </td>\n",
    "</tr>\n",
    "    <tr>\n",
    "<td> Model 3 </td> <td> Default </td> <td> Aug. data, NAs filled by 2-layer NN predictions </td> <td> 50 epochs </td>\n",
    "</tr>\n",
    "    <tr>\n",
    "<td> Model 4 </td> <td> Add dropout layers </td> <td> Aug. data, NAs filled by 2-layer NN predictions </td> <td> 50 epochs </td>\n",
    "</tr>\n",
    "    <tr>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = build_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_NN(model1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "hist1, runtime1 = train_model(\n",
    "    model1, train_data_orig, train_labels_orig, \n",
    "    dev_data_orig, dev_labels_orig, epochs=50\n",
    ")\n",
    "\n",
    "# save off the history\n",
    "history1 = pd.DataFrame(hist1.history)\n",
    "history1.to_csv('history_model1.csv')\n",
    "\n",
    "# predict on test data and format for kaggle submission\n",
    "pred1 = predict_for_kaggle(model1, test_data, 'kaggle_model1.csv'):\n",
    "\n",
    "# store the results\n",
    "result_dict['CNN Model1'] = [\n",
    "    round(np.sqrt(hist1.history['loss'][-1]) * 48,2), \n",
    "    round(np.sqrt(hist1.history['val_loss'][-1]) * 48,2),\n",
    "    round(np.sum(runtime1.times),2)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could try running this for longer, but the way the validation loss levels off even as the training loss continues to shrink shows that the model is overfitting. This is unsurprising given the small size of our data set, and the large number of parameters. For better results, we should next try the full (unaugmented) data set and see how it fares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = build_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "hist2, runtime2 = train_model(\n",
    "    model2, train_data_aug, train_labels_aug, \n",
    "    dev_data_orig, dev_labels_orig, epochs=50\n",
    ")\n",
    "\n",
    "# save off the history\n",
    "history2 = pd.DataFrame(hist2.history)\n",
    "history2.to_csv('history_model2.csv')\n",
    "\n",
    "# predict on test data and format for kaggle submission\n",
    "pred2 = predict_for_kaggle(model2, test_data, 'kaggle_model2.csv'):\n",
    "\n",
    "# store the results\n",
    "result_dict['CNN Model2'] = [\n",
    "    round(np.sqrt(hist2.history['loss'][-1]) * 48,2), \n",
    "    round(np.sqrt(hist2.history['val_loss'][-1]) * 48,2), \n",
    "    round(np.sum(runtime2.times),2)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This did significantly better and the validation loss was still improving alongside the training loss at the end of ten epochs. Given this continued improvement, it would be worth running this for longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict missing values\n",
    "A large percentage of the points are missing, meaning we are not using a large percentage of the information we have in the dataset. However facial keypoints will, in general, follow location patterns across images of faces. Uing a simple two layer neural net we use the moset commonly labeled key points to predict values for the features that are not labeled in a majority of the data. Then we can fill the missing labels in with these predicted points and retrain the data with no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the 2-layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basicNN = Sequential()\n",
    "basicNN.add(Dense(units=1000,activation='relu'))\n",
    "basicNN.add(Dense(units=1000,activation='relu'))\n",
    "basicNN.add(Dense(units=1000,activation='relu'))\n",
    "\n",
    "# create the output layer\n",
    "basicNN.add(Dense(units=30))\n",
    "\n",
    "# compile the model\n",
    "basicNN.compile(loss=mean_squared_error_with_missing, optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_hist, NN_time = train_model(\n",
    "    basicNN,\n",
    "    train_labels_aug_comp[:,[0,1,2,3,20,21,28,29]], train_labels_aug_comp,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, len(train_data_aug), 16)\n",
    "data_sample = train_data_aug[idx, :, :, :]\n",
    "\n",
    "pred = basicNN.predict(train_labels_aug[:,[0,1,2,3,20,21,28,29]])\n",
    "\n",
    "label_sample = pred[idx, :]\n",
    "label_sample_true = train_labels_aug[idx, :]\n",
    "\n",
    "plot_sample(data_sample, label_sample_true, labels2=label_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels_full = train_labels_aug.copy()\n",
    "for i in range(train_labels_full.shape[1]):\n",
    "    for j,v in enumerate(train_labels_full[:,i]):\n",
    "        if np.isnan(v):\n",
    "            train_labels_full[j,i] = pred[j,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment some data or change a parameter\n",
    "model3 = build_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_NN(model3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing against augmented dev data with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "hist3, runtime3 = train_model(\n",
    "    model3, train_data_aug, train_labels_full, \n",
    "    dev_data_orig, dev_labels_orig, epochs=50\n",
    ")\n",
    "\n",
    "# save off the history\n",
    "history3 = pd.DataFrame(hist3.history)\n",
    "history3.to_csv('history_model3.csv')\n",
    "\n",
    "# predict on test data and format for kaggle submission\n",
    "pred3 = predict_for_kaggle(model3, test_data, 'kaggle_model3.csv'):\n",
    "\n",
    "# store the results\n",
    "result_dict['CNN Model3'] = [\n",
    "    round(np.sqrt(hist3.history['loss'][-1]) * 48,2), \n",
    "    round(np.sqrt(hist3.history['val_loss'][-1]) * 48,2), \n",
    "    round(np.sum(runtime3.times),2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding droput layers\n",
    "model4 = build_CNN(dropout=[0.1,0.2,0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_NN(model4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing against augmented dev data with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train the model\n",
    "hist4, runtime4 = train_model(\n",
    "    model4, train_data_aug, train_labels_full, \n",
    "    dev_data_orig, dev_labels_orig, epochs=50\n",
    ")\n",
    "\n",
    "# save off the history\n",
    "history4 = pd.DataFrame(hist4.history)\n",
    "history4.to_csv('history_model4.csv')\n",
    "\n",
    "# predict on test data and format for kaggle submission\n",
    "pred4 = predict_for_kaggle(model4, test_data, 'kaggle_model4.csv'):\n",
    "    \n",
    "# store the results\n",
    "result_dict['CNN Model4'] = [\n",
    "    round(np.sqrt(hist4.history['loss'][-1]) * 48,2), \n",
    "    round(np.sqrt(hist4.history['val_loss'][-1]) * 48,2), \n",
    "    round(np.sum(runtime3.times),2)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize training improvement\n",
    "Doesn't look like an improvement, but it will once we train on the whole data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist1 = pd.read_csv('history_model1.csv')\n",
    "hist2 = pd.read_csv('history_model2.csv')\n",
    "hist3 = pd.read_csv('history_model3.csv')\n",
    "hist4 = pd.read_csv('history_model4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val_rms1 = hist1.history['val_loss']\n",
    "# train_rms1 = hist1.history['loss']\n",
    "# val_rms2 = hist2.history['val_loss']\n",
    "# train_rms2 = hist2.history['loss']\n",
    "# val_rms3 = hist3.history['val_loss']\n",
    "# train_rms3 = hist3.history['loss']\n",
    "# val_rms4 = hist4.history['val_loss']\n",
    "# train_rms4 = hist4.history['loss']\n",
    "\n",
    "val_rms1 = hist1['val_loss']\n",
    "train_rms1 = hist1['loss']\n",
    "val_rms2 = hist2['val_loss']\n",
    "train_rms2 = hist2['loss']\n",
    "val_rms3 = hist3['val_loss']\n",
    "train_rms3 = hist3['loss']\n",
    "val_rms4 = hist4['val_loss']\n",
    "train_rms4 = hist4['loss']\n",
    "\n",
    "fig = plt.figure(figsize=(10,10))\n",
    "plt.semilogy(val_rms1, 'g-')\n",
    "plt.semilogy(train_rms1, 'g--')\n",
    "plt.semilogy(val_rms2, 'b-')\n",
    "plt.semilogy(train_rms2, 'b--')\n",
    "plt.semilogy(val_rms3, 'r-')\n",
    "plt.semilogy(train_rms3, 'r--')\n",
    "plt.semilogy(val_rms4, 'k-')\n",
    "plt.semilogy(train_rms4, 'k--')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss - Mean Squared Error')\n",
    "\n",
    "ax.legend([\n",
    "    'Orig. Data Only - Val. Loss', 'Orig. Data Only - Train Loss',\n",
    "    'Orig. Data + Aug. - Val. Loss', 'Orig. Data + Aug. - Train Loss',\n",
    "    'Orig. Data + Aug. + Pred. NAs - Val. Loss', 'Orig. Data + Aug. + Pred. NAs - Train Loss',\n",
    "    'Add Dropout layers - Val. Loss', 'Add Dropout layers - Train Loss',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat these steps for each final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, len(test_data), 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data = test_data[idx]\n",
    "pred_labels1 = pred1[idx]\n",
    "pred_labels2 = pred2[idx]\n",
    "pred_labels3 = pred3[idx]\n",
    "pred_labels4 = pred4[idx]\n",
    "sample_labels = np.concatenate(\n",
    "    [pred_labels1, pred_labels2, pred_labels3, pred_labels4], axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(4,4,figsize=(10,10))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "colors = {'r','b','g','k'}\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        ax = axes[i,j]\n",
    "        img = sample_data[j].reshape(96,96)\n",
    "        labels = sample_labels[i,j]\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.scatter(labels[0::2] * 48 + 48, labels[1::2] * 48 + 48, c=colors[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put a conclusion here comparing and contrasting the models and how well we did on Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict['Idx Values'] = ['Training RMSE', 'Development RMSE', 'Training Time (s)']\n",
    "summary = pd.DataFrame.from_dict(result_dict)\n",
    "summary = summary.set_index(['Idx Values'])\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - http://deeplearning.net/tutorial/lenet.html#lenet\n",
    " - https://arxiv.org/abs/1206.5533\n",
    " - https://arxiv.org/abs/1412.6980v8\n",
    " - http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/\n",
    " - https://arxiv.org/abs/1710.05279\n",
    " - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4978658/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Daniel Nouri model transferred to Keras (as best as I could)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "DEADLINE --> Wednesday\n",
    "\n",
    "- Reorg - Alex\n",
    "- Step 1 - Research question/Intro\n",
    "    - how can we accurately predict pixel locations of facial keypoints?\n",
    "    - map out high level plan of attack\n",
    "- Step 2 - EDA\n",
    "    - Explore data - all\n",
    "    - examining edge cases - Mark\n",
    "    - Make decisions on NA values, data to keep - Mark\n",
    "        - to think about --> possibly doing augmentations on portions on the dataset for development\n",
    "    - Explanation of why we are using a custom loss function rather than filling NA values with some guess at the feature location - all\n",
    "- Step 3 - Feature engineering/augmentation --> 3-4 augmentations maximum\n",
    "    - Prepocess\n",
    "        - gaussian blur --> yes - Tennison\n",
    "    - Augmentation\n",
    "        - Flip images --> yes - Alex\n",
    "        - darken and lighten (either this or normalize) - Tennison\n",
    "        - rotate --> maybe - Tennison/Maddie\n",
    "        - Zooming/cropping --> maybe\n",
    "    - try to correct errors from simple models\n",
    "- Step 4 - Define success\n",
    "    - train on simple models for baseline comparison\n",
    "        - 'DecisionTree': DecisionTreeRegressor(), # Maddie\n",
    "        - 'NearestNeighbors': KNeighborsRegressor(), # Tennison\n",
    "        - 'NaiveBayes': NaiveBayes(), # Mark\n",
    "        - 'LogisticRegression': LogisticRegression() # Alex\n",
    "        - why did we choose these simple models? - all\n",
    "            - Everyone choose their own model, not linear regression\n",
    "            - motivation section\n",
    "            - run the model\n",
    "            - why didn't it work?\n",
    "        - examine how models are handling missing values\n",
    "        - try augmentations on each model\n",
    "    - look at error (RMS, absolute, others?) as well as training time\n",
    "- Step 5 - Examine errors on simple models - all\n",
    "    - Determine why errors are occurring\n",
    "- Step 6 - build models\n",
    "    - train a CNN model on each augmentation\n",
    "    - Need to explain model hyperparameter choices - Alex/All\n",
    "        - number of layers\n",
    "        - number of filters\n",
    "        - optimizer\n",
    "        - activation --> 'relu' industry standard\n",
    "- Step 7 - predict / measure success - all\n",
    "    - Summary table of performance\n",
    "    - predict on test data\n",
    "    - get Kaggle score\n",
    "    - defeat Trump\n",
    "- step 8 - site sources - all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# making a callback so I can compare runtimes\n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# first group of layers\n",
    "model.add(Conv2D(\n",
    "    32, \n",
    "    kernel_size=(3,3), \n",
    "    activation='relu',\n",
    "    input_shape=(96, 96, 1), \n",
    "#     data_format='channels_first'\n",
    "))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# second group of layers\n",
    "model.add(Conv2D(\n",
    "    64, \n",
    "    kernel_size=(2, 2), \n",
    "    activation='relu'\n",
    "))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "# third group of layers\n",
    "model.add(Conv2D(\n",
    "    128, \n",
    "    kernel_size=(2, 2), \n",
    "    activation='relu'\n",
    "))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(30))\n",
    "\n",
    "sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='mean_squared_error', optimizer=sgd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "time_callback = TimeHistory()\n",
    "hist = model.fit(\n",
    "    train_data, train_labels, \n",
    "    batch_size=32,\n",
    "    epochs=4,\n",
    "    validation_split=0.2, \n",
    "    verbose=1,\n",
    "    callbacks=[keras.callbacks.History(), time_callback]\n",
    ")\n",
    "print('RMS error on validation set:', np.sqrt(hist.history['val_loss'][-1]) * 48)\n",
    "print('Total runtime (minutes):', round(np.sum(time_callback.times) / 60, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Alex trying to understand..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# FIRST CONVOLUTIONAL LAYER\n",
    "model.add(Conv2D(\n",
    "    filters=32, # don't yet fully understand how to choose this dimension\n",
    "    kernel_size=(3,3),\n",
    "    strides=(1,1),\n",
    "    padding='same',\n",
    "    activation='relu',\n",
    "    input_shape=(96, 96, 1),\n",
    "))\n",
    "# input_shape = (batch, rows, cols, channels) --> (batch, 96, 96, 1)\n",
    "# padding = 'same' so for a kernel of size (3,3) and strides=(1,1) this \n",
    "# will pad two rows and two columns of zeros on the edges so that the \n",
    "# output shape gives an tensor with 96 rows and 96 columns\n",
    "# output_shape = (batch, new_rows, new_cols, filters) --> (batch, 96, 96, 32)\n",
    "\n",
    "# POOLING LAYER\n",
    "model.add(MaxPooling2D(\n",
    "    pool_size=(2,2),\n",
    "    strides=None\n",
    "))\n",
    "# setting strides=None sets the strides to a default of pool_size, so \n",
    "# here we are really setting strides=(2,2) which is what we want so we \n",
    "# don't miss any pixels and we don't count any pixels more than once\n",
    "# the strides is essentially the factor by which to downscale the output\n",
    "# so setting the strides=(2,2) will have the dimensions of input\n",
    "# output_shape = (batch, in_rows/strides[0], in_cols/strides[1], filters) --> (batch, 48, 48, 32)\n",
    "\n",
    "\n",
    "# SECOND CONVOLUTIONAL LAYER\n",
    "model.add(Conv2D(\n",
    "    filters=64, # don't know why we increased this number by 2\n",
    "#     kernel_size=(2, 2),\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1,1),\n",
    "    padding='same',\n",
    "    activation='relu'\n",
    "))\n",
    "# input_shape = (batch, pool_rows, pool_cols, in_filters) --> (batch, 48, 48, 32)\n",
    "# output_shape = (batch, new_rows, new_cols, out_filters) --> (batch, 48, 48, 64)\n",
    "\n",
    "# SECOND POOLING LAYER\n",
    "model.add(MaxPooling2D(\n",
    "    pool_size=(2, 2), \n",
    "    strides=None\n",
    "))\n",
    "# input_shape = (batch, in_rows, in_cols, filters) --> (batch, 48, 48, 64)\n",
    "# output_shape = (batch, in_rows/strides[0], in_cols/strides[1], filters) --> (batch, 24, 24, 64)\n",
    "\n",
    "# THIRD CONVOLUTIONAL LAYER\n",
    "model.add(Conv2D(\n",
    "    filters=128, # don't know how to choose this value\n",
    "#     kernel_size=(2, 2),\n",
    "    kernel_size=(3, 3),\n",
    "    strides=(1,1),\n",
    "    padding='same',\n",
    "    activation='relu'\n",
    "))\n",
    "# input_shape = (batch, pool_rows, pool_cols, in_filters) --> (batch, 24, 24, 64)\n",
    "# output_shape = (batch, new_rows, new_cols, out_filters) --> (batch, 24, 24, 128)\n",
    "\n",
    "# THIRD POOLING LAYER\n",
    "model.add(MaxPooling2D(\n",
    "    pool_size=(2, 2),\n",
    "    strides=None\n",
    "))\n",
    "# input_shape = (batch, in_rows, in_cols, filters) --> (batch, 24, 24, 128)\n",
    "# output_shape = (batch, in_rows/strides[0], in_cols/strides[1], filters) --> (batch, 12, 12, 128)\n",
    "\n",
    "# FLATTEN THE POOLED OUTPUT TO CLASSIFY\n",
    "model.add(Flatten())\n",
    "# flatten the output into a single layer of \n",
    "#     shape = [batch, pool_rows * pool_cols * in_filters]\n",
    "#         --> [batch, 12 * 12 * 128] = [batch, 18432]\n",
    "\n",
    "# ADD ONE FULLY CONNECTED LAYER TO PROCESS THE FLATTENED DATA\n",
    "model.add(Dense(\n",
    "#     500,\n",
    "    1000,\n",
    "    activation='relu'\n",
    "))\n",
    "# input_shape = [batch, flattened_nodes] = [batch, 18432]\n",
    "# output_shape = [batch, out_nodes] = [batch, 500]\n",
    "\n",
    "# FINAL OUTPUT LAYER\n",
    "model.add(Dense(30))\n",
    "# input_shape = [batch, in_nodes] = [batch, 500]\n",
    "# output_shape = [batch, num_classes] = [batch, 30]\n",
    "\n",
    "# sgd = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "adam = keras.optimizers.Adam()\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "time_callback = TimeHistory()\n",
    "hist = model.fit(\n",
    "    train_data, train_labels, \n",
    "    batch_size=32,\n",
    "    epochs=4, \n",
    "    validation_split=0.2, \n",
    "    verbose=1,\n",
    "    callbacks=[keras.callbacks.History(), time_callback]\n",
    ")\n",
    "print('\\nRMS error on validation set:', np.sqrt(hist.history['val_loss'][-1]) * 48)\n",
    "print('Total runtime (minutes):', round(np.sum(time_callback.times) / 60, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Changed the kernel size in the second two layers to (3,3), almost doubled the training time, didn't improve the error by a lot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# move this cell closer to the top, but putting it here now for convenience in referencing for cell below.\n",
    "i = 0\n",
    "feature_dict = {}\n",
    "for label in train.columns[:-1].values:\n",
    "# for label in features:\n",
    "    feature_dict[label] = i\n",
    "    i += 1\n",
    "print(feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Naive baseline - calculate the average (X, Y) of all the labels and \n",
    "# guess that every time\n",
    "n_rows = train_data.shape[0]\n",
    "n_cols = train_data.iloc[0].shape[0]\n",
    "\n",
    "for col in [1]: #range(n_cols):\n",
    "    sum = 0\n",
    "    for row in range(n_rows):\n",
    "        sum += train_labels.iloc[row][col]\n",
    "    avg = sum / n_rows\n",
    "    predictions = np.ones(dev_data.shape[0]) * avg\n",
    "\n",
    "    mse = mean_squared_error(dev_labels['left_eye_center_x'], predictions)\n",
    "    print(mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Define the model as a KerasRegressor class\n",
    "\n",
    "model = KerasRegressor(build_fn=build_CNN, epochs=10)\n",
    "\n",
    "# Define parameter ranges over which to search\n",
    "\n",
    "f = list(range(8,72,8))\n",
    "filts = [[i, i*2, i*4] for i in f]\n",
    "filts, len(filts)\n",
    "\n",
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']\n",
    "\n",
    "k1 = [[(i,i)]*3 for i in range(2,5)]\n",
    "k2 = [\n",
    "    [(4,4), (3,3), (2,2)], \n",
    "    [(3,3), (2,2), (2,2)], \n",
    "    [(2,2), (3,3), (4,4)],\n",
    "    [(2,2), (2,2), (3,3)],\n",
    "    [(3,3), (3,3), (2,2)],\n",
    "    [(2,2), (3,3), (3,3)],\n",
    "]\n",
    "k = k1 + k2\n",
    "k, len(k)\n",
    "\n",
    "# param_grid = dict(optimizer=optimizer, filters=filts, kernels=k)\n",
    "# param_grid = dict(optimizer=optimizer, kernels=k)\n",
    "param_grid = dict(kernels=k)\n",
    "param_grid\n",
    "\n",
    "# Run the grid search\n",
    "\n",
    "grid = GridSearchCV(\n",
    "    estimator=model, \n",
    "    param_grid=param_grid, \n",
    "#     n_jobs=-1,\n",
    "    scoring='neg_mean_squared_error',\n",
    ")\n",
    "\n",
    "grid_data, grid_labels = shuffle(train_data_set, train_labels_set, random_state=666)\n",
    "grid_data, grid_labels = grid_data[:100], grid_labels[:100]\n",
    "grid_data.shape, grid_labels.shape\n",
    "\n",
    "grid_result = grid.fit(grid_data, grid_labels, verbose=1)\n",
    "\n",
    "# Get the results and store to csv\n",
    "\n",
    "cv_results = pd.DataFrame(grid_result.cv_results_)\n",
    "cv_results.head()\n",
    "cv_results.to_csv('grid_search_results2.csv')\n",
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Lighten/Darken Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# From here: https://en.wikipedia.org/wiki/Normalization_(image_processing)\n",
    "def normalize_image(data, min = 0, max = 255):\n",
    "\n",
    "    new_dataset = []\n",
    "    split_data = np.split(data, data.shape[0])\n",
    "    \n",
    "    for image in split_data:\n",
    "        image = np.squeeze(image)\n",
    "        \n",
    "        image = image * 255\n",
    "        \n",
    "        old_min, old_max, old_avg = np.amin(image), np.amax(image), np.mean(image)        \n",
    "        new_min, new_max, new_avg = min, max, max-min/2\n",
    "        \n",
    "        mfactor = old_avg/new_avg\n",
    "\n",
    "        new_image = []\n",
    "        \n",
    "        for pixel in image.flatten():\n",
    "            #new_pixel = int((pixel-old_min)*((new_max-new_min)/(old_max-old_min))+ new_min)\n",
    "            new_pixel = pixel * mfactor\n",
    "            new_image.append(new_pixel)\n",
    "        \n",
    "        new_image = np.array(new_image)/ 255\n",
    "        new_image = new_image.reshape(96, 96, 1)\n",
    "        \n",
    "        new_dataset.append(new_image)\n",
    "    \n",
    "    return np.stack(new_dataset, axis=0 )\n",
    "\n",
    "train_data_normalized = normalize_image(train_data)\n",
    "test_data_normalized = normalize_image(test_data)\n",
    "\n",
    "f, axarr = plt.subplots(1, 2, figsize=(10,10), sharex=True, sharey=True)\n",
    "\n",
    "print (train_data[1].flatten())\n",
    "print (train_data_normalized[1].flatten())\n",
    "\n",
    "axarr[0].imshow(train_data[1].reshape(96,96), cmap='gray')\n",
    "axarr[1].imshow(train_data_normalized[1].reshape(96,96), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Test for augmentation\n",
    "\n",
    "image = np.squeeze(crop_data[2])\n",
    "\n",
    "print (image.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(image, cmap='gray')\n",
    "\n",
    "#for c in range(0, crop_labels.shape[1], 2):\n",
    "#    x = crop_labels[111][c]* 48 + 48\n",
    "#    y = crop_labels[111][c+1]* 48 + 48\n",
    "        \n",
    "#    plt.scatter(x,y,cmap='pastel1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "images = np.random.randint(0, 255, (16, 128, 128, 3), dtype=np.uint8)\n",
    "print (images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# additional interesting cases to explore if time allows:\n",
    "# - multiple faces in one image\n",
    "# - upside down faces\n",
    "# - incomplete faces (not all key points present)\n",
    "# - race/lighting (average shade of pixels in facial region, plot couple darkest/lightest)\n",
    "# - faces halfway offscreen/covered (could try one eye present, one not), image 154 has eyes and nose but mouth offscreen\n",
    "# - additonal edge cases discovered incidentally \n",
    "#    - sunglasses (1802)\n",
    "\n",
    "#  - eventually will want to manually remove 2153, 4971 is questionable depending on which points those are\n",
    "\n",
    "# edge_cases.extend((train_labels[:,feature_dict['right_eye_center_x']] -\n",
    "#                    train_labels[:,feature_dict['left_eye_center_x']]).argsort()[-7:]) # small faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # original data, no missing values (for training the sklearn baseline models)\n",
    "# train_data_complete = train_data_complete\n",
    "# train_labels_complete = train_labels_complete\n",
    "# dev_data_complete = dev_data_complete\n",
    "# dev_labels_complete = dev_labels_complete\n",
    "\n",
    "# # original data with missing values (for first pass of CNN)\n",
    "# train_data_orig = train_data\n",
    "# train_labels_orig = train_labels\n",
    "# dev_data_orig = dev_data\n",
    "# dev_labels_orig = dev_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# ALEX: The guess-the-average baseline was breaking so I modifed it here\n",
    "# and moved the original to the appendix. If we want to keep this we \n",
    "# probably want to do somethign smarter with the NA's rather than just \n",
    "# drop them\n",
    "\n",
    "    # Convert arrays of arrays to a numpy matrix or sklearn .fit doesn't like them.\n",
    "#     X = np.empty((train_data.shape[0], train_data.iloc[0].shape[0]))\n",
    "#     for row in range(train_data.shape[0]):\n",
    "#         X[row,:] = train_data.iloc[row]\n",
    "#     Z = np.empty((dev_data.shape[0], dev_data.iloc[0].shape[0]))\n",
    "#     for row in range(dev_data.shape[0]):\n",
    "#         Z[row,:] = dev_data.iloc[row]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "flipped_dev_data, flipped_dev_labels = mirror_data(\n",
    "    dev_data_orig, dev_labels_orig, list(feature_dict.keys())\n",
    ")\n",
    "\n",
    "flipped_dev_data_complete, flipped_dev_labels_complete = mirror_data(\n",
    "    dev_data_complete, dev_labels_complete, list(feature_dict.keys())\n",
    ")\n",
    "\n",
    "\n",
    "dev_data_aug = np.concatenate(\n",
    "    (dev_data_orig,\n",
    "     flipped_dev_data, \n",
    "     contrast_dev_data, \n",
    "     blur_dev_data, \n",
    "     rotate_dev_data), \n",
    "    axis=0\n",
    ")\n",
    "dev_labels_aug = np.concatenate(\n",
    "    (dev_labels_orig, \n",
    "     flipped_dev_labels, \n",
    "     contrast_dev_labels, \n",
    "     blur_dev_labels, \n",
    "     rotate_dev_labels), \n",
    "    axis=0\n",
    "    \n",
    ")\n",
    "\n",
    "\n",
    "dev_data_aug_comp = np.concatenate(\n",
    "    (dev_data_complete,\n",
    "     flipped_dev_data_complete, \n",
    "     contrast_dev_data_complete, \n",
    "     blur_dev_data_complete, \n",
    "     rotate_dev_data_complete), \n",
    "    axis=0\n",
    ")\n",
    "dev_labels_aug_comp = np.concatenate(\n",
    "    (dev_labels_complete,\n",
    "     flipped_dev_labels_complete, \n",
    "     contrast_dev_labels_complete, \n",
    "     blur_dev_labels_complete, \n",
    "     rotate_dev_labels_complete\n",
    "    ), \n",
    "    axis=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# delete all single augmentation sets to preserve memory\n",
    "del flipped_data, contrast_data, blur_data, rotate_data, flipped_labels, contrast_labels, blur_labels, rotate_labels, flipped_dev_data, contrast_dev_data, blur_dev_data, rotate_dev_data,flipped_dev_labels, contrast_dev_labels, blur_dev_labels, rotate_dev_labels,flipped_data_complete, contrast_data_complete, blur_data_complete, rotate_data_complete,flipped_labels_complete, contrast_labels_complete, blur_labels_complete, rotate_labels_complete,contrast_dev_data_complete, blur_dev_data_complete, rotate_dev_data_complete,flipped_dev_labels_complete, contrast_dev_labels_complete, blur_dev_labels_complete, rotate_dev_labels_complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Predict values for your chosen model\n",
    "pred = model3.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Get the list of required test points\n",
    "lookup = pd.read_csv('IdLookupTable.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#Match up the test points with the predicted values\n",
    "\n",
    "labelNums = {}\n",
    "for index, label in enumerate(train.columns.values):\n",
    "    labelNums[label] = index\n",
    "    \n",
    "lookup['FeatureNum'] = lookup.apply(lambda row: labelNums[row['FeatureName']], axis=1)\n",
    "lookup.Location =  np.minimum(96,np.maximum(0,pred[lookup.ImageId-1,lookup.FeatureNum]*48 + 48))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# save the rowid and the associated location to a csv\n",
    "\n",
    "lookup.to_csv(path_or_buf='kagglesubmission.csv',columns=['RowId','Location'],index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3virtualenv",
   "language": "python",
   "name": "py3virtualenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
