{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W207 Final Project: Facial Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Team: MapReduce, MapReuse, MapRecycle\n",
    "Members: Tennison Yu, Madeleine Bulkow, Mark Paluta, Alex Dauenhauer\n",
    "\n",
    "https://github.com/tyu0912/MIDS_W207_facial_recognition/issues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This is the final project submission from Team MapReduce,MapReuse,MapRecycle for W207: Applied Machine Learning as part of the MIDS program at UC Berkeley. We are working with data from https://www.kaggle.com/c/facial-keypoints-detection/data and the goal is to accurately identify facial features on an (x, y) coordinate system based on an input image. \n",
    "\n",
    "## Overall Project Flow\n",
    "\n",
    "Our project is layed out into the following parts:\n",
    "\n",
    "1) EDA - We explore the data and see what the images and labels we are working with are like\n",
    "\n",
    "2) Feature Engineering - We alter/augment images to expand our training set to better cover edge cases and generalize the algorithm. Based on our exploration of common standard techniques done, we decided to flip, contrast, blur, and rotate the images.\n",
    "\n",
    "3) Simple Modeling - We explore the effectiveness of simple algorithms such as Decision Trees and Neast Neighbors and compare and contrast their effectiveness. \n",
    "\n",
    "4) Complex Modeling - We explore the effectiveness of a more complex model, convoluted neural networks (CNN).\n",
    "\n",
    "5) Summary and Apply - We present our findings and apply our best predictive algorithm to the test data that Kaggle provided us to see how well we did. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages, Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:40:06.820663Z",
     "start_time": "2018-12-10T03:40:06.815674Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Optional cell to install/update all required packages\n",
    "# ! pip install keras tensorflow numpy pandas matplotlib scipy imgaug opencv-python pydot graphviz > nul\n",
    "# ! conda install shapely > nul\n",
    "# print('Packages installed, output supressed for cleanliness')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:40:11.129152Z",
     "start_time": "2018-12-10T03:40:06.827644Z"
    }
   },
   "outputs": [],
   "source": [
    "import time, sys, os, keras, tensorflow as tf, warnings, imgaug as ia\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, pydot, graphviz\n",
    "from importlib import reload\n",
    "from sklearn.utils import shuffle\n",
    "from keras import backend as K\n",
    "from keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from keras.utils import plot_model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "from scipy import stats\n",
    "from imgaug import augmenters as iaa\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "\n",
    "\n",
    "# set tensorflow as keras backend\n",
    "if K.backend() not in [\"tensorflow\", 'plaidml']:\n",
    "    print ('Switching keras backend...')\n",
    "    os.environ['KERAS_BACKEND'] = \"tensorflow\"\n",
    "    reload(K)\n",
    "    \n",
    "print('keras version:', keras.__version__)\n",
    "print('tensorflow version:', tf.__version__)\n",
    "print('pandas version:', pd.__version__)\n",
    "print('numpy version:', np.__version__)\n",
    "\n",
    "# Initiate settings and load the data.\n",
    "np.random.seed(0)\n",
    "pd.options.display.max_columns = 30\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "train = pd.read_csv('training.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print ('Everything Loaded Successfully')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We begin by exploring our data. It is important to understand the range of values we can take on, whether there is missing data, and whether there might be erroneous data. We will be exploring primarily on the image level, as opposed to on the individual keypoint or pixel level, because pixels and keypoints tell a much more important story via their relationship to one another rather than in isolation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Glancing at the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will see the format our data is in. They keypoints are provided in x or y coordinate floats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:40:11.203952Z",
     "start_time": "2018-12-10T03:40:11.136133Z"
    }
   },
   "outputs": [],
   "source": [
    "train[train.columns[:-1]].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pixels are in a greyscale 8-bit format (range 0 to 255)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:40:11.225895Z",
     "start_time": "2018-12-10T03:40:11.206947Z"
    }
   },
   "outputs": [],
   "source": [
    "train['Image'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our first interesting observation is that not all of the images contain all keypoints. In fact no keypoint is present in every image and many are present in less than half of the images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:40:11.256811Z",
     "start_time": "2018-12-10T03:40:11.228886Z"
    }
   },
   "outputs": [],
   "source": [
    "print(train.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above cells, we can see that we are given x,y coordinates for our different features in seperate columns. As well, images are currently strings with each pixel value separated by a space. We will need to manipulate these to a form we can work with such as numpy arrays.\n",
    "\n",
    "Additionally, many labels have a lot of missing data. The only label that is complete appears to be the nose tip."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformating the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems for complex models such as the CNN, keras requires the data to be in numpy array form with dimensions = (batch, image_width, image_height, num_channels). Images in dataset are 96x96 grayscale images, therefore shape should be (X, 96, 96, 1).\n",
    "\n",
    "To ensure we have data to work stored away for development, we will also split the training set into 80% train data and 20% dev data in the steps below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:40:11.272768Z",
     "start_time": "2018-12-10T03:40:11.259804Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def process_datasets(df, test=False, fillna=False, dropna=False):\n",
    "    '''This function reformats the data from a dataframe to a numpy\n",
    "    array of the appropriate shape.\n",
    "    '''\n",
    "\n",
    "    # whether or not to remove images with missing labels\n",
    "    if dropna:\n",
    "        df = df.dropna()\n",
    "    \n",
    "    # build feature dict for reference in future functions\n",
    "    feature_dict = {label:i for i,label in enumerate(df.columns[:-1].values)}\n",
    "    \n",
    "    # separate images into numpy arrays\n",
    "    images_pixel_feature = df.Image.apply(lambda im: np.fromstring(im, sep=' '))\n",
    "    \n",
    "    # rescale pixel values to [0,1] interval and reshape\n",
    "    images_pixel_feature = np.stack(images_pixel_feature) / 255\n",
    "    images_pixel_feature = images_pixel_feature.reshape(-1, 96, 96, 1)\n",
    "    \n",
    "    \n",
    "    # separate the labels and scale them to [-1,1] interval for use of \n",
    "    # rectified linear unit activation\n",
    "    if not test:\n",
    "        facial_point_labels = df.iloc[:, :-1]\n",
    "        if fillna:\n",
    "            facial_point_labels.fillna(np.mean(facial_point_labels, axis=0), inplace=True)\n",
    "        facial_point_labels = facial_point_labels.values\n",
    "        facial_point_labels = (facial_point_labels - 48) / 48\n",
    "    else:\n",
    "        facial_point_labels = None\n",
    "    \n",
    "    return images_pixel_feature, facial_point_labels, feature_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:40:36.125380Z",
     "start_time": "2018-12-10T03:40:11.275761Z"
    }
   },
   "outputs": [],
   "source": [
    "# Raw data\n",
    "# train_raw = processed but not split\n",
    "train_data_raw, train_labels_raw, feature_dict = process_datasets(train)\n",
    "test_data, test_labels, _ = process_datasets(test, test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Random Sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we wanted to observe some sample images with labels to see what kind of variety of images we are working with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:40:36.138346Z",
     "start_time": "2018-12-10T03:40:36.127374Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_sample(data, labels, labels2=None):\n",
    "    '''\n",
    "    data must be a numpy.ndarray of shape (X, 96, 96, 1)\n",
    "    labels must be a numpy.ndarray (X, 30)\n",
    "    X must be any square number\n",
    "    labels = true labels\n",
    "    labesl2 = predicted labels (optional)\n",
    "    '''\n",
    "    \n",
    "    dim = np.sqrt(len(data))\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "    for i in range(len(labels)):\n",
    "        img = data[i].reshape(96,96)\n",
    "        ax = fig.add_subplot(dim, dim, i + 1, xticks=[], yticks=[])\n",
    "        ax.imshow(data[i].reshape(96,96), cmap='gray')\n",
    "        ax.scatter(labels[i][0::2] * 48 + 48, labels[i][1::2] * 48 + 48, c='r')\n",
    "        if not labels2 is None:\n",
    "            ax.scatter(labels2[i][0::2] * 48 + 48, labels2[i][1::2] * 48 + 48, c='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:40:37.235423Z",
     "start_time": "2018-12-10T03:40:36.141338Z"
    }
   },
   "outputs": [],
   "source": [
    "# Output sample of random images. Some of these will be the NA data\n",
    "n = 25\n",
    "idx = np.random.randint(0, len(train_data_raw), n)\n",
    "data_sample = train_data_raw[idx, :, :, :]\n",
    "label_sample = train_labels_raw[idx, :]\n",
    "plot_sample(data_sample, label_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Edge Cases\n",
    "\n",
    "In addition to random faces, we wondered what some edge cases are like. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:40:37.515667Z",
     "start_time": "2018-12-10T03:40:37.237409Z"
    }
   },
   "outputs": [],
   "source": [
    "edge_cases = []\n",
    "\n",
    "# --- compile interesting cases --- \n",
    "\n",
    "# noses on the side of the image may imply a profile shot\n",
    "edge_cases.extend(train_labels_raw[:,feature_dict['nose_tip_x']].argsort()[:8])           # left profiles\n",
    "edge_cases.extend(train_labels_raw[:,feature_dict['nose_tip_x']].argsort()[-8:])          # right profiles\n",
    "\n",
    "# max differential in eye height will imply clocking\n",
    "edge_cases.extend((train_labels_raw[:,feature_dict['right_eye_center_y']] -               # faces clocked right\n",
    "                   train_labels_raw[:,feature_dict['left_eye_center_y']]).argsort()[:8])  \n",
    "edge_cases.extend((train_labels_raw[:,feature_dict['left_eye_center_y']] -                # faces clocked left\n",
    "                   train_labels_raw[:,feature_dict['right_eye_center_y']]).argsort()[:8]) \n",
    "\n",
    "# faces vary in width\n",
    "edge_cases.extend((train_labels_raw[:,feature_dict['right_eye_center_x']] -               # wide faces\n",
    "                   train_labels_raw[:,feature_dict['left_eye_center_x']]).argsort()[:8])  \n",
    "edge_cases.extend((train_labels_raw[:,feature_dict['left_eye_center_x']] -                # thin faces\n",
    "                   train_labels_raw[:,feature_dict['right_eye_center_x']]).argsort()[:8]) \n",
    "\n",
    "# investigate very dark or light faces to see if we have different races or lighting\n",
    "edge_cases.extend(np.sum(train_data_raw.reshape(train_data_raw.shape[0], 96*96), axis=1).argsort()[:8])      # dark faces\n",
    "edge_cases.extend(np.sum(train_data_raw.reshape(train_data_raw.shape[0], 96*96), axis=1).argsort()[-8:])     # light faces\n",
    "\n",
    "print(len(edge_cases), edge_cases)\n",
    "\n",
    "data_edge = train_data_raw[edge_cases, :, :, :]\n",
    "label_edge = train_labels_raw[edge_cases, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rows of the following image are meant to illustrate, respectively:\n",
    "- left profiles\n",
    "- right profiles\n",
    "- clocked right\n",
    "- clocked left\n",
    "- wide faces\n",
    "- thin faces\n",
    "- dark faces\n",
    "- light faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:40:40.138657Z",
     "start_time": "2018-12-10T03:40:37.518657Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_sample(data_edge, label_edge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above, it looks like there are several different types of edge cases. We can see there are a variety of angles, lighting, tilts, resolutions, and even a drawing (bottom right corner). Some cases look like purely bad data that may need to be removed such as the first picture of Leonardo DiCaprio. Also interesting is that there are images that are the same subject."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing erroneous data  \n",
    "To remove the data that we considered bad data, we utilized a method that will be covered in our appendix to flag likely erroneous images. They are printed here to confirm that they indeed look erroneous, and then we throw them out for the remainder of our project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:40:43.121691Z",
     "start_time": "2018-12-10T03:40:40.142648Z"
    }
   },
   "outputs": [],
   "source": [
    "# hard code in flagged images\n",
    "flagged = [1230, 1620, 1649, 1652, 1723, 1747, 1808, 1834, 1861, 1877, 1881, 1907, 1927, 1942, 1966, 1995,\n",
    "           2036, 2096, 2175, 2191, 2199, 2244, 2289, 2453, 2484, 2533, 2562, 2629, 2664, 2700, 2787, 2818,\n",
    "           2831, 2845, 2982, 3087, 3173, 3296, 3307, 3374, 3447, 3487, 3510, 3647, 3888, 4180, 4263, 4480,\n",
    "           4482, 4490, 4601, 4717, 4786, 5117, 5795, 5952, 6082, 6271, 6315, 6405, 6407, 6492, 6493, 6569,\n",
    "           6585, 6765, 6782, 6834, 6906]\n",
    "\n",
    "# plot these images as a sanity check that they are in fact \"bad\" data\n",
    "i = 0\n",
    "rows = 8\n",
    "cols = len(flagged)//rows + 1\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "for index in flagged:\n",
    "    ax = fig.add_subplot(rows, cols, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(train_data_raw[index].reshape(96,96), cmap='gray')\n",
    "    ax.scatter(train_labels_raw[index][0::2] * 48 + 48, train_labels_raw[i][1::2] * 48 + 48, c='r')\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:40:43.500676Z",
     "start_time": "2018-12-10T03:40:43.124682Z"
    }
   },
   "outputs": [],
   "source": [
    "# Delete these images from the data set forever\n",
    "train_data_raw = np.delete(train_data_raw, flagged, 0)\n",
    "train_labels_raw = np.delete(train_labels_raw, flagged, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because there are so many images with incomplete values, we now need to define another set with NA removed that will be used later on to train simple baseline models as well as predict the position of the missing labels for later training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:40:49.246326Z",
     "start_time": "2018-12-10T03:40:43.503671Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dropping NAs\n",
    "# drop bad data from original dataframe\n",
    "train = train.drop(flagged)\n",
    "\n",
    "# train_complete = no missing values\n",
    "train_data_complete, train_labels_complete, _ = process_datasets(train, dropna=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:40:49.644268Z",
     "start_time": "2018-12-10T03:40:49.248322Z"
    }
   },
   "outputs": [],
   "source": [
    "### DON'T RUN THIS CELL MORE THAN ONCE WITHOUT RE-RUNNING PROCESS DATASETS! ###\n",
    "\n",
    "# 20% of the data will go to dev\n",
    "percent_to_dev = 0.2 \n",
    "\n",
    "# Note the naming convention change.\n",
    "# train_orig = with missing values\n",
    "\n",
    "train_data_orig, dev_data_orig, train_labels_orig, dev_labels_orig = train_test_split(\n",
    "    train_data_raw, train_labels_raw, test_size=percent_to_dev\n",
    ")\n",
    "train_data_complete, dev_data_complete, train_labels_complete, dev_labels_complete = train_test_split(\n",
    "    train_data_complete, train_labels_complete, test_size=percent_to_dev\n",
    ")\n",
    "\n",
    "print(\"\\nTrain data shape\", train_data_orig.shape)\n",
    "print(\"Dev data shape\", dev_data_orig.shape)\n",
    "print(\"Train labels shape\", train_labels_orig.shape)\n",
    "print(\"Dev labels shape\", dev_labels_orig.shape)\n",
    "print(\"\\nTrain data no-missing-values shape\", train_data_complete.shape)\n",
    "print(\"Dev data no-missing-values shape\", dev_data_complete.shape)\n",
    "print(\"Train labels no-missing-values shape\", train_labels_complete.shape)\n",
    "print(\"Dev labels no-missing-values shape\", dev_labels_complete.shape)\n",
    "\n",
    "print(\"\\nData Generation Finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be sure our training set has enough variety to predict well on the observed edge cases, we expand the variety of our data set even more. We decided to create sets of images that were mirrored, altered contrast, blurred, and rotated as it seems these are the most prevalent gestures of the different faces. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T22:51:04.409121Z",
     "start_time": "2018-12-09T22:51:04.395084Z"
    },
    "code_folding": [
     2,
     37
    ]
   },
   "outputs": [],
   "source": [
    "# We use the imgaug library to generate our new sets of images\n",
    "\n",
    "def augment_images(data, labels, aug):\n",
    "    \n",
    "    data = data * 255\n",
    "    aug_labels =[]\n",
    "    seq_det = aug.to_deterministic()\n",
    "    aug_data = seq_det.augment_images(data)\n",
    "    \n",
    "    keypoints_on_images = []\n",
    "    \n",
    "    for features in labels:\n",
    "        keypoints = []\n",
    "        \n",
    "        for c in range(0, features.shape[0], 2):\n",
    "            x = features[c]* 48 + 48\n",
    "            y = features[c+1]* 48 + 48\n",
    "\n",
    "            keypoints.append(ia.Keypoint(x=x, y=y))\n",
    "\n",
    "        keypoints_on_images.append(ia.KeypointsOnImage(keypoints, shape=(96,96)))\n",
    "    \n",
    "    keypoints_aug = seq_det.augment_keypoints(keypoints_on_images)    \n",
    "        \n",
    "    for keypoints_after in keypoints_aug:\n",
    "        aug_labels_set = []\n",
    "        \n",
    "        for i, keypoint in enumerate(keypoints_after.keypoints):\n",
    "            aug_labels_set.append((keypoint.x - 48) / 48)\n",
    "            aug_labels_set.append((keypoint.y - 48) / 48)\n",
    "                \n",
    "        aug_labels.append(aug_labels_set)\n",
    "        \n",
    "    return aug_data/255, np.array(aug_labels)\n",
    "\n",
    "# The imgaug library confuses the labels in the case of mirroring an image so we made our own custom method. \n",
    "\n",
    "def mirror_data(data, labels, features):\n",
    "    '''This function flips the images and labels to their new columns\n",
    "    Input data is numpy array of shape (X, 96, 96, 1)\n",
    "    Input labels is numpy array of shape (X, 30)\n",
    "    features is a list of column header strings\n",
    "    '''\n",
    "    \n",
    "    # flip the images\n",
    "    data_flipped = data[:, :, ::-1, :]\n",
    "    \n",
    "    # flip the labels\n",
    "    labels_flipped = np.zeros(labels.shape)\n",
    "    for idx in range(len(labels)):\n",
    "        for i,s1 in enumerate(features):\n",
    "            parts = s1.partition('_')\n",
    "            if parts[0] == 'left' or parts[0] == 'right':\n",
    "                coord = parts[-1]\n",
    "            elif parts[0] == 'mouth':\n",
    "                parts = s1.split('_', maxsplit=2)\n",
    "                if 'corner' in parts[-1]:\n",
    "                    coord = parts[-1]        \n",
    "                elif 'x' in parts[-1]:\n",
    "                    labels_flipped[idx,i] = labels[idx,i] * -1\n",
    "                else:\n",
    "                    labels_flipped[idx,i] = labels[idx,i]\n",
    "            else:\n",
    "                if 'x' in parts[-1]:\n",
    "                    labels_flipped[idx,i] = labels[idx,i] * -1\n",
    "                else:\n",
    "                    labels_flipped[idx,i] = labels[idx,i]\n",
    "            for j in range(i+1,len(features)-1):\n",
    "                s2 = features[j]\n",
    "                if coord in s2:\n",
    "                    if 'x' in coord:\n",
    "                        labels_flipped[idx,i] = labels[idx,j] * -1\n",
    "                        labels_flipped[idx,j] = labels[idx,i] * -1\n",
    "                    else:\n",
    "                        labels_flipped[idx,i] = labels[idx,j]\n",
    "                        labels_flipped[idx,j] = labels[idx,i]\n",
    "                \n",
    "    return data_flipped, labels_flipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T22:51:05.566225Z",
     "start_time": "2018-12-09T22:51:04.411130Z"
    }
   },
   "outputs": [],
   "source": [
    "# mirror training and dev data\n",
    "flipped_data, flipped_labels = mirror_data(\n",
    "    train_data_orig, train_labels_orig, list(feature_dict.keys())\n",
    ")\n",
    "\n",
    "flipped_data_complete, flipped_labels_complete = mirror_data(\n",
    "    train_data_complete, train_labels_complete, list(feature_dict.keys())\n",
    ")\n",
    "\n",
    "# Concatanating to make new set\n",
    "\n",
    "# Note the new naming convention\n",
    "# train_aug = augmented with missing values  \n",
    "# train_aug_comp = augmented no missing values\n",
    "\n",
    "train_data_aug = np.concatenate((train_data_orig,flipped_data), axis=0)\n",
    "train_labels_aug =  np.concatenate((train_labels_orig, flipped_labels), axis=0)\n",
    "\n",
    "train_data_aug_comp = np.concatenate((train_data_complete, flipped_data_complete),axis=0)\n",
    "train_labels_aug_comp = np.concatenate((train_labels_complete,flipped_labels_complete),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We test applying 1,2 or 3 of blurring, contrast to the data. \n",
    "# We do this randomly to make sure everything is equally distributed.\n",
    "\n",
    "aug_test = iaa.Sometimes(1,  iaa.SomeOf((1, 3), \n",
    "            [iaa.GammaContrast((0.25, 3)),\n",
    "             iaa.GaussianBlur(sigma=1),\n",
    "             iaa.Affine(rotate=(-10,10), scale={\"x\": (1.05, 1.2), \"y\": (1.05, 1.2)})\n",
    "            ]                        \n",
    "        )\n",
    "    )\n",
    "\n",
    "fig, axes = plt.subplots(1,6,figsize=(20,10))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "\n",
    "for i in range(6):\n",
    "    test_data_aug, test_labels_aug = augment_images(np.expand_dims(train_data_aug_comp[0], axis=0), np.expand_dims(train_labels_aug_comp[0], axis=0), aug_test)\n",
    "    ax = axes[i]\n",
    "    \n",
    "    if i == 0:\n",
    "        ax.set_title('Original', fontsize=20)\n",
    "        ax.imshow(train_data_aug_comp[0].reshape(96,96), cmap='gray')\n",
    "    else:\n",
    "        ax.set_title('Sample Aug {i}'.format(i=i), fontsize=20)\n",
    "        ax.imshow(test_data_aug.reshape(96,96), cmap='gray')\n",
    "    \n",
    "    ax.scatter(test_labels_aug[0][0::2] * 48 + 48, test_labels_aug[0][1::2] * 48 + 48, c='r')\n",
    "    ax.axis('off')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T22:51:17.711163Z",
     "start_time": "2018-12-09T22:51:05.567252Z"
    }
   },
   "outputs": [],
   "source": [
    "# We apply the above to to 50% of the data so that there\n",
    "# is an even amount of unmanipulated and manipulated data.\n",
    "\n",
    "aug = iaa.Sometimes(0.5,  iaa.SomeOf((1, 3), \n",
    "            [iaa.GammaContrast((0.25, 3)),\n",
    "             iaa.GaussianBlur(sigma=1),\n",
    "             iaa.Affine(rotate=(-10,10), scale={\"x\": (1.05, 1.2), \"y\": (1.05, 1.2)})\n",
    "            ]                        \n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "train_data_aug, train_labels_aug = augment_images(train_data_aug, train_labels_aug, aug)\n",
    "train_data_aug_comp, train_labels_aug_comp = augment_images(train_data_aug_comp, train_labels_aug_comp, aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T22:51:17.717215Z",
     "start_time": "2018-12-09T22:51:17.711163Z"
    }
   },
   "outputs": [],
   "source": [
    "img1 = train_data_orig[0].reshape(96,96)\n",
    "lab1 = train_labels_orig[0]\n",
    "img2 = train_data_aug[0].reshape(96,96)\n",
    "lab2 = train_labels_aug[0]\n",
    "img3 = train_data_orig[1].reshape(96,96)\n",
    "lab3 = train_labels_orig[1]\n",
    "img4 = train_data_aug[1].reshape(96,96)\n",
    "lab4 = train_labels_aug[1]\n",
    "img5 = train_data_orig[2].reshape(96,96)\n",
    "lab5 = train_labels_orig[2]\n",
    "img6 = train_data_aug[2].reshape(96,96)\n",
    "lab6 = train_labels_aug[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T22:51:18.110266Z",
     "start_time": "2018-12-09T22:51:17.719221Z"
    }
   },
   "outputs": [],
   "source": [
    "imgs = [img1, img2, img3, img4, img5, img6]\n",
    "labs = [lab1, lab2, lab3, lab4, lab5, lab6]\n",
    "titles = ['original 1','augmented 1','original 2','augmented 2','original 3', 'augmented 3']\n",
    "\n",
    "fig, axes = plt.subplots(1,6,figsize=(20,10))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "for i in range(6):\n",
    "    ax = axes[i]\n",
    "    ax.imshow(imgs[i], cmap='gray')\n",
    "    ax.scatter(labs[i][0::2] * 48 + 48, labs[i][1::2] * 48 + 48, c='r')\n",
    "    ax.axis('off')\n",
    "    ax.set_title(titles[i], fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that the augmentations worked. Note again that the augmentations are applied to only 50% of the data so there may be some images above that are not augmented. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Establish Baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin our modeling, we select common supervised-learning regression algorithms such as linear regression, k-nearest neighbors, decision tree and random forest for baselines to compare our CNN to. The thought process behind choosing each one is described below. However, given existing literature, it seems CNN is the preferred way to solve problems of this nature. Therefore greater emphasis will be given for that technique. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Kaggle Output**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T22:51:18.115275Z",
     "start_time": "2018-12-09T22:51:18.112267Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict_for_kaggle(model, test_data, filename):\n",
    "    \n",
    "    #Predict values for your chosen model\n",
    "    try:\n",
    "        pred = model.predict(test_data)\n",
    "    except:\n",
    "        pred = model\n",
    "    \n",
    "    # Get the list of required test points\n",
    "    lookup = pd.read_csv('IdLookupTable.csv')\n",
    "    \n",
    "    #Match up the test points with the predicted values\n",
    "    labelNums = {}\n",
    "    for index, label in enumerate(train.columns.values):\n",
    "        labelNums[label] = index\n",
    "    lookup['FeatureNum'] = lookup.apply(\n",
    "        lambda row: labelNums[row['FeatureName']], axis=1\n",
    "    )\n",
    "    lookup.Location =  np.minimum(\n",
    "        96, np.maximum(0, pred[lookup.ImageId-1, lookup.FeatureNum]*48 + 48)\n",
    "    )\n",
    "    \n",
    "    # save the rowid and the associated location to a csv\n",
    "    lookup.to_csv(\n",
    "        path_or_buf=filename, columns=['RowId','Location'], index=False\n",
    "    )\n",
    "    \n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To begin our modeling, in a similar fashion to Shi (2017), we select common supervised-learning regression algorithms such as linear regression, k-nearest neighbors, decision tree and random forest for baselines to compare our CNN to. The thought process behind choosing each one is described below. However, given existing literature, it seems CNN is the preferred way to solve problems of this nature. Therefore greater emphasis will be given for that technique. The choice of these algorithms is also partially inspired by https://scikit-learn.org/stable/auto_examples/plot_multioutput_face_completion.html#sphx-glr-auto-examples-plot-multioutput-face-completion-py "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start off by seeing how different the average location is for each feature versus the different images themselves. This gives a \"no work done\" baseline to compare future results to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T20:28:24.767093Z",
     "start_time": "2018-12-09T20:28:24.749045Z"
    }
   },
   "outputs": [],
   "source": [
    "# As a simple test, we want to look at the average of all the features and what the error of that would be. \n",
    "# We use the complete set to avoid issues with incomplete values. \n",
    "\n",
    "avg_dict = {}\n",
    "\n",
    "avg_position = np.mean(train_labels_aug_comp, axis=0)\n",
    "predictions = np.ones(train_labels_aug_comp.shape) * avg_position\n",
    "mse = np.sqrt(mean_squared_error(train_labels_aug_comp, predictions)) * 48\n",
    "avg_dict['Training Average'] = [None, None, None, predictions]\n",
    "\n",
    "predict_for_kaggle(predictions, test_data, 'average_result_kaggle.csv')\n",
    "\n",
    "print ('The RMSE error when predicting average value for each label:', mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will model the data using the chosen baseline models. The models will run pre-optimized as the grid search portions of the code were done prior to assignment submission. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T20:28:24.780132Z",
     "start_time": "2018-12-09T20:28:24.770101Z"
    }
   },
   "outputs": [],
   "source": [
    "# More simple baselines\n",
    "regressors = {\n",
    "    'LinearRegression': LinearRegression(normalize = True),\n",
    "    'DecisionTree': DecisionTreeRegressor(random_state=0, min_samples_split=2),\n",
    "    'RandomForest': RandomForestRegressor(random_state=0, min_samples_split=2, n_estimators=6),\n",
    "    'NearestNeighbors': KNeighborsRegressor(weights='uniform', metric='euclidean')\n",
    "} \n",
    "\n",
    "# Optimization Parameters\n",
    "\n",
    "parameters = {\n",
    "    'RandomForest': {'n_estimators': [6,8,10,12]}, \n",
    "    'DecisionTree': {'min_samples_split': [2,3,4]},\n",
    "    'NearestNeighbors':  {'weights': ['uniform','distance'], 'metric': ['euclidean','manhattan','minkowski']}, \n",
    "    'LinearRegression': {'fit_intercept': [True, False], 'normalize':[True, False]}\n",
    "}\n",
    "\n",
    "rmse_scorer = make_scorer(mean_squared_error)\n",
    "\n",
    "def model_training(dict_name, model, parameters, train_data, labels, dev_data, dev_labels, test_data, grid = False):\n",
    "    X = train_data.reshape(-1, 96**2)\n",
    "    Y = labels\n",
    "    \n",
    "    if grid == True:        \n",
    "        grid_obj = GridSearchCV(model, parameters, scoring=rmse_scorer)\n",
    "        grid_obj = grid_obj.fit(X, Y)\n",
    "        \n",
    "        print(grid_obj.best_params_)\n",
    "        \n",
    "        regressor = grid_obj.best_estimator_\n",
    "        start=datetime.now()\n",
    "        regressor.fit(X, Y)\n",
    "        runtime = datetime.now() - start\n",
    "        predictions = regressor.predict(X)\n",
    "        \n",
    "        train_mse = np.sqrt(mean_squared_error(Y, predictions)) * 48\n",
    "\n",
    "        Z = dev_data.reshape(-1, 96**2)\n",
    "\n",
    "        predictions = regressor.predict(Z)\n",
    "        dev_mse = np.sqrt(mean_squared_error(dev_labels, predictions)) * 48\n",
    "        \n",
    "        predict_for_kaggle(regressor, test_data.reshape(-1, 96**2), dict_name +'_kaggle.csv')\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        start=datetime.now()\n",
    "        model.fit(X,Y)\n",
    "        runtime = datetime.now() - start\n",
    "\n",
    "        predictions = model.predict(X)\n",
    "        train_mse = np.sqrt(mean_squared_error(Y, predictions)) * 48\n",
    "\n",
    "        Z = dev_data.reshape(-1, 96**2)\n",
    "\n",
    "        predictions = model.predict(Z)\n",
    "        dev_mse = np.sqrt(mean_squared_error(dev_labels, predictions)) * 48\n",
    "        \n",
    "        predict_for_kaggle(model, test_data.reshape(-1, 96**2), dict_name +'_kaggle.csv')\n",
    "    \n",
    "    return [round(train_mse,2), round(dev_mse,2), round(runtime.seconds,2), predictions]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T20:31:48.581100Z",
     "start_time": "2018-12-09T20:28:24.782133Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train_basic_models(which_set, avg_dict, train_data, train_labels, dev_data, dev_labels, test_data, grid = False):\n",
    "    if which_set == 'complete':\n",
    "        print ('This is with the complete set')\n",
    "    elif which_set == 'complete_aug':\n",
    "        print ('This is with the complete_aug set')\n",
    "    \n",
    "    basic_models = {}\n",
    "    \n",
    "    for k,v in regressors.items():\n",
    "        p = parameters[k]\n",
    "        \n",
    "        if which_set == 'complete':\n",
    "            dict_name = k + '_complete'\n",
    "        elif which_set == 'complete_aug':\n",
    "            dict_name = k + '_complete_aug'\n",
    "        \n",
    "        result = model_training(dict_name, v, p, train_data, train_labels, dev_data, dev_labels, test_data, grid)\n",
    "        \n",
    "        basic_models[dict_name] = result\n",
    "        \n",
    "        print('\\n', k,':\\n',\n",
    "              'Training RMSE=', result[0],\n",
    "              'Dev RMSE=', result[1],\n",
    "              'Train Time=', result[2]\n",
    "             )\n",
    "\n",
    "    img_idx = 2\n",
    "    img = train_data_complete[img_idx].reshape(96,96)\n",
    "\n",
    "    fig, axes = plt.subplots(1,len(basic_models) + 1,figsize=(15,15))\n",
    "    fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "\n",
    "    print ('\\nResults Below. Red = Actual Labels  Blue = Predicted Labels\\n')\n",
    "    \n",
    "    ax = axes[0]\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    ax.scatter(train_labels_complete[img_idx][0::2] * 48 + 48, train_labels_complete[img_idx][1::2] * 48 + 48, c='r')\n",
    "    ax.scatter(avg_dict['Training Average'][3][img_idx][0::2] * 48 + 48, avg_dict['Training Average'][3][img_idx][1::2] * 48 + 48, c='b')\n",
    "    ax.axis('off')\n",
    "    ax.set_title('Training Average', fontsize=11)\n",
    "    \n",
    "    for i,(k,v) in enumerate(basic_models.items()):\n",
    "        ax = axes[i+1]\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.scatter(train_labels_complete[img_idx][0::2] * 48 + 48, train_labels_complete[img_idx][1::2] * 48 + 48, c='r')\n",
    "        ax.scatter(v[3][img_idx][0::2] * 48 + 48, v[3][img_idx][1::2] * 48 + 48, c='b')\n",
    "        ax.axis('off')\n",
    "        ax.set_title(k, fontsize=15)\n",
    "        \n",
    "    return basic_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T20:41:04.314090Z",
     "start_time": "2018-12-09T20:31:48.583105Z"
    }
   },
   "outputs": [],
   "source": [
    "results_comp = train_basic_models('complete', avg_dict, train_data_complete, train_labels_complete, dev_data_complete, dev_labels_complete, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_comp_aug = train_basic_models('complete_aug', avg_dict, train_data_aug_comp, train_labels_aug_comp, dev_data_complete, dev_labels_complete, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dicts(*dict_args):\n",
    "    result = {}\n",
    "    for dictionary in dict_args:\n",
    "        result.update(dictionary)\n",
    "    return result\n",
    "\n",
    "result_dict = merge_dicts(avg_dict, results_comp, results_comp_aug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Results\n",
    "\n",
    "Without augmentations, it seems that kNN performs the best followed by Random Forest and Linear Regression. This isn't surprising as kNN essentially assigns the k points by it's closest values. As supplemented below, all facial features are approximately at the same location on the face. With Decision Trees and Random Forests, a single Decision Tree performs the worst but after aggregating to a Random Forest, the algorithm performs a lot better. Random Forests typically reduce variance by training on different samples of the data. Another way that it reduces overfitting is that it uses a random subset of features each time. This allows the overall algorithm to generalize better.\n",
    "\n",
    "When looking at the augmented result, kNN and Random Forest retain their performance ranking however linear regression performs much more poorly. This is likely to do with the manipulated images being introduced. We elaborate further on its weakness below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n",
    "**Rational:** Linear regression essentially minimizes the squared error distance between actual and predicted values. This was picked because of its simplicity and it would be interesting to gauge the performance of a classical regressor.\n",
    "\n",
    "**Weakness:** With a smaller training set size, the RMSE is comparable to that of the other algorithms however once the training set increases, the RMSE gets much worse. This likely means that the algorithm performs poorly with extreme variation in the labels and the images they map to. This is not unexpected as linear models assume a linear relationship between independent variables and the dependent variables. This would not apply to facial positions especially if they are not all full frontal shots. Therefore, it is likely not reliable as an algorithm moving forward.\n",
    "\n",
    "**Future:** There are other linear modeling techniques such as Lasso and ElasticNet which add regularization terms that often are used to reduce overfitting. The results would be interesting to see however the assumption of a linear relationship still applies. Also the choosing of the regularization parameter would warrant some deep investigation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest/Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rational:** A decision tree is a non-parametric supervised learning method that predicts the value of a target variable by establishing decision rules inferred from the data features. Random forests are just a set of decision trees results where a consensus value has been established either by voting or averaging. We ran a random forest as well because of the weaknesses as described below. \n",
    "\n",
    "**Weakness:** By itself, this decision tree algorithm seemed to perform the worst after linear regression. It could be that we have overfitted the model since decisions can be very complex and is very sensitive to small variations. Tree are also known to ignore the correlation between features, which is highly the case in this experiment. For instance, knowing the position of one eye can often tell you the position of the other eye.\n",
    "\n",
    "**Future:** Hyperparameter tuning to improve performance include pruning, setting the minimum number of samples required at a leaf node or setting the maximum depth."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Rational:** We pick kNN because all facial features are on the same location on the face i.e left eye is on the upper left, right eye is on the upper right, nose is in the middle, etc. Because kNN work by assigning a query point as those of its neighbors, given a set of images, kNN should be able to figure out which pixels is generally associated with the eye area, the nose area, etc.\n",
    "\n",
    "**Weakness:** One potential weakness of this algorithm may be images where the face located off center. For example, if an image has a face translated to the right, then it may mistake the left eye on the image for a right eye\n",
    "\n",
    "**Future:** One of the corner stones of knn is the idea of distance and how that is defined. We have found that Euclidean is better than the default Minknowski distance set by sklearn however the use of correlation might be more appropriate since as described above, the position of features on a face are all correlated in some sense. In other studies, Chi square distance also seems to perform well. Both of these would be worth engineering and exploring in the future. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build a custom loss function to handle NA values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:18:39.661067Z",
     "start_time": "2018-12-10T03:18:39.655087Z"
    }
   },
   "outputs": [],
   "source": [
    "# building a time callback to track total runtime\n",
    "class TimeHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.times = []\n",
    "\n",
    "    def on_epoch_begin(self, batch, logs={}):\n",
    "        self.epoch_time_start = time.time()\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.times.append(time.time() - self.epoch_time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:18:40.379868Z",
     "start_time": "2018-12-10T03:18:40.374877Z"
    }
   },
   "outputs": [],
   "source": [
    "# building a custom loss function to handle NAs\n",
    "def mean_squared_error_with_missing(y_true, y_pred):\n",
    "    \n",
    "    # figure out which labels are present\n",
    "    present = tf.logical_not(tf.is_nan(y_true))\n",
    "    \n",
    "    # select only those labels\n",
    "    present_labels_true = tf.boolean_mask(y_true, present)\n",
    "    present_labels_pred = tf.boolean_mask(y_pred, present)\n",
    "    \n",
    "    # compute mean squared error\n",
    "    loss = tf.math.reduce_mean(tf.math.squared_difference(present_labels_true,present_labels_pred))\n",
    "    \n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:19:16.389670Z",
     "start_time": "2018-12-10T03:19:16.100436Z"
    }
   },
   "outputs": [],
   "source": [
    "mod = plt.imread('model.png')\n",
    "fig = plt.figure(figsize=(10,20), frameon=False)\n",
    "plt.imshow(mod)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Parameter and Hyper-parameter selection:**\n",
    "\n",
    "The Convolutional Neural Network (CNN) has many parameters to choose to build the model. We first need to determine how many layer stacks the model should have. Each layer stack should contain, at a minimum, a convolutional layer and a pooling layer. You can also choose to add a dropout layer at each stack, to help avoid overfitting on the training set.  For each convolutional layer, we need to determine the shape of the convolutional kernel, as well the shape of the pooling kernel. After the convolutional layer stack, the output needs to be flattened and we need to determine the number of dense layers to send it through before generating the output. Again we can choose to add dropout layers here or not. After we have decided on the shape our network will take, we need to determine the optimizer to use, and the loss function. The optimizer comes with its own set of hyperparameters, the most important of which is the initial learning rate according to Bengio.\n",
    "\n",
    "**Optimizer:**  \n",
    "Per Bengio, for stochastic gradient descent (SGD) optimization, \"The optimal learning rate is usually close to the largest learning rate that does not cause divergence of the training criterion.\" His suggestion is to start with a large learning rate and if the training criterion diverges, decrease the learning rate by a factor of 3. Due to hardware memory limitations, we were unable to carry out full hyperparameter tuning via grid search. So rather than search for the optimal SGD learning rate, we chose to use an adaptive optimizer called Adam which converges much faster than standard SGD. Adam is an adaptation/enhancement to SGD. Whereas SGD uses a single learning rate for all weight updates and does not update the learning rate during training, the Adam optimizer \"calculates an exponential moving average of the gradient and the squared gradient.\" The hyperparameters beta1 and beta2 control the decay rates of these moving averages. Because the authors of the Adam optimizer performed hyperparameter tuning on a similar convolutional neural net built for prediction on the MNIST data set, we used the default values of the Adam optimizer which are currently set to the optimal values determined by the authors.\n",
    "\n",
    "**Number of Layers:**  \n",
    "Again according to Bengio, \"the optimal number layers can be determine by simply adding layers until the error does not improve anymore.\" As we were using the Daniel Nouri tutorial as a guide to building the CNN, we started with three convolutional/pooling layer pairs in our CNN. We tested 4 and 5 layer pairs as well which gave little to no improvement in the loss on the validation data, but did increase the training time significantly, so we decided on three layer pairs for the default value of the model. \n",
    "\n",
    "**Number of filters:**  \n",
    "Each filter in a convolutional layer can be thought of as a single feature detector. In the initial layer, the filters will be able to detect simple geometric patterns such as a lines or curves. As we go deeper in the network, the feature detectors can become more sophisticated. Since we want to predict the position of 15 facial keypoints varying in shape and size and orientation, we need to have enough feature detectors by the last layer to handle a large variety of features. We tried various combinations of factors of 2 for the number of filters in each layer, with the number of filters multiplying by 2 at each layer. After some trial and error, we settled on 32, 64, 128 filters for convolutional layers 1, 2, and 3 respectively. \n",
    "\n",
    "**Pooling layers:**  \n",
    "The pooling layers determine the factor by which you downscale your data after each convolutional layer. We chose to simply use pooling kernels of (2,2) with a stride of (2,2) so that our output shape at each layer was easy to keep track of\n",
    "\n",
    "**Number of Dense layers and Dense layer nodes:**  \n",
    "Admittedly, we spent more of our time tuning the parameters in the convolutional stack than in the dense layer section of the model, but we did test some variations ranging from 1 layer with 100 nodes to 3 layers of 2000 nodes and ended up settling on 2 layers with 1000 nodes each for our default model values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:18:42.923895Z",
     "start_time": "2018-12-10T03:18:42.906940Z"
    },
    "code_folding": [
     11
    ]
   },
   "outputs": [],
   "source": [
    "def build_CNN(\n",
    "    num_ConvLayers=3, \n",
    "    num_DenseLayers=2,\n",
    "    filters=[32,64,128],\n",
    "    kernels=[(3,3),(3,3),(3,3)], \n",
    "    pools=[(2,2),(2,2),(2,2)], \n",
    "    dense_nodes=[1000,1000], \n",
    "    optimizer='Adam', \n",
    "    dropout=None,\n",
    "    input_shape=(96,96,1),\n",
    "    loss=mean_squared_error_with_missing\n",
    "):\n",
    "    '''This function builds a CNN model\n",
    "    num_ConvLayers --> is the number of convolutional layer groups where \n",
    "    each group contains a convolutional layer, a pooling layer, and an\n",
    "    optional dropout layer\n",
    "    \n",
    "    num_DenseLayers --> is the number of dense layers after flattening\n",
    "    the convolutional output\n",
    "    \n",
    "    filters --> a list of the number of filters used in each\n",
    "    convolutional layer specified in num_ConvLayers\n",
    "    \n",
    "    kernels --> a list of the kernel size to use in each convolutional\n",
    "    layer specified in num_ConvLayers\n",
    "    \n",
    "    pools --> a list of the kernel size to use in each pooling layer\n",
    "    specified in num_ConvLayers\n",
    "    \n",
    "    dense_nodes --> a list of the number of units in each dense layer\n",
    "    specified in num_DenseLayers\n",
    "    \n",
    "    dropout --> optional, a list of the dropout rates at each \n",
    "    convolutional layer\n",
    "    \n",
    "    input_shape --> the shape of the input data\n",
    "    '''\n",
    "    # define a Sequential model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # add convolutional layer groups\n",
    "    for i in range(num_ConvLayers):\n",
    "        model.add(Conv2D(\n",
    "            filters=filters[i],\n",
    "            kernel_size=kernels[i],\n",
    "            strides=(1,1),\n",
    "            padding='same',\n",
    "            activation='relu',\n",
    "            input_shape=input_shape\n",
    "        ))\n",
    "        model.add(MaxPooling2D(\n",
    "            pool_size=pools[i],\n",
    "            strides=None\n",
    "        ))\n",
    "        \n",
    "        # add dropout layers if specified\n",
    "        if dropout:\n",
    "            model.add(Dropout(rate=dropout[i]))\n",
    "    \n",
    "    # flatten the convolutional layers\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # add the dense layers\n",
    "    for j in range(num_DenseLayers):\n",
    "        model.add(Dense(\n",
    "            units=dense_nodes[j],\n",
    "            activation='relu'\n",
    "        ))\n",
    "        \n",
    "    # create the output layer\n",
    "    model.add(Dense(units=30))\n",
    "    \n",
    "    # compile the model\n",
    "    model.compile(loss=loss, optimizer=optimizer)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T22:51:18.172426Z",
     "start_time": "2018-12-09T22:51:18.164404Z"
    },
    "code_folding": [
     7
    ]
   },
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model, \n",
    "    train_data, train_labels, \n",
    "    dev_data=None, dev_labels=None,\n",
    "    batch_size=32,\n",
    "    verbose=1,\n",
    "    epochs=10\n",
    "):\n",
    "    time_callback = TimeHistory()\n",
    "    hist = keras.callbacks.History()\n",
    "    if not dev_data is None:\n",
    "        model.fit(\n",
    "            train_data, train_labels, \n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs, \n",
    "            validation_data=(dev_data, dev_labels),\n",
    "            verbose=verbose,\n",
    "            callbacks=[hist, time_callback]\n",
    "        )\n",
    "    else:\n",
    "        model.fit(\n",
    "            train_data, train_labels, \n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs, \n",
    "            validation_split=0.2,\n",
    "            verbose=verbose,\n",
    "            callbacks=[hist, time_callback]\n",
    "        )\n",
    "    print('\\nRMS error on validation set:', np.sqrt(hist.history['val_loss'][-1]) * 48)\n",
    "    print('Total runtime (minutes):', round(np.sum(time_callback.times) / 60, 2))\n",
    "    \n",
    "    return hist, time_callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Running CNN\n",
    "the below table contains a layout of our training plan. The 0th model will be trained on the complete data set (no missing values) for performance comparison against the simple baseline models. The first true model will be trained on the original dataset with missing values and no augmentations applied. The second model will use the original dataset with all augmentations applied. The third model will use the augmented data with NAs filled by 2-layer NN predictions. The fourth model will be the same as model 3 but we will utilize dropout layers to prevent overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table> \n",
    "<tr>\n",
    "<th> Model Name </th> <th> Model Parameters </th> <th> Data </th> <th> Training Criteria </th>\n",
    "</tr>\n",
    "<tr>\n",
    "<td> Model 0a </td> <td> Default </td> <td> Complete Data </td> <td> 50 epochs </td>\n",
    "</tr>\n",
    "    <tr>\n",
    "<td> Model 0b </td> <td> Default </td> <td> Complete Data + Augmentations </td> <td> 50 epochs </td>\n",
    "</tr>\n",
    "    <tr>\n",
    "<td> Model 1 </td> <td> Default </td> <td> Original Data </td> <td> 50 epochs </td>\n",
    "</tr>\n",
    "    <tr>\n",
    "<td> Model 2 </td> <td> Default </td> <td> Original Data + Augmentations </td> <td> 50 epochs </td>\n",
    "</tr>\n",
    "    <tr>\n",
    "<td> Model 3 </td> <td> Default </td> <td> Aug. data, NAs filled by 2-layer NN predictions </td> <td> 50 epochs </td>\n",
    "</tr>\n",
    "    <tr>\n",
    "<td> Model 4 </td> <td> Add dropout layers </td> <td> Aug. data, NAs filled by 2-layer NN predictions </td> <td> 50 epochs </td>\n",
    "</tr>\n",
    "    <tr>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T22:14:44.523314Z",
     "start_time": "2018-12-09T22:14:44.313701Z"
    }
   },
   "outputs": [],
   "source": [
    "model0a = build_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T22:19:23.802879Z",
     "start_time": "2018-12-09T22:14:44.525264Z"
    }
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "hist0a, runtime0a = train_model(\n",
    "    model0a, train_data_complete, train_labels_complete, \n",
    "    dev_data_complete, dev_labels_complete, epochs=50\n",
    ")\n",
    "\n",
    "# save off the history\n",
    "history0a = pd.DataFrame(hist0a.history)\n",
    "history0a.to_csv('history_model0a.csv')\n",
    "\n",
    "# predict on test data and format for kaggle submission\n",
    "pred0a = predict_for_kaggle(model0a, test_data, 'kaggle_model0a.csv')\n",
    "\n",
    "# store the results\n",
    "result_dict['CNN Model0a'] = [\n",
    "    round(np.sqrt(hist0a.history['loss'][-1]) * 48,2), \n",
    "    round(np.sqrt(hist0a.history['val_loss'][-1]) * 48,2),\n",
    "    round(np.sum(runtime0a.times),2)\n",
    "]\n",
    "df = pd.DataFrame(result_dict)\n",
    "with open('results.csv','a') as f:\n",
    "    df.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T22:19:23.994382Z",
     "start_time": "2018-12-09T22:19:23.802879Z"
    }
   },
   "outputs": [],
   "source": [
    "model0b = build_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T22:28:17.107286Z",
     "start_time": "2018-12-09T22:19:23.995377Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "hist0b, runtime0b = train_model(\n",
    "    model0b, train_data_aug_comp, train_labels_aug_comp, \n",
    "    dev_data_complete, dev_labels_complete, epochs=50\n",
    ")\n",
    "\n",
    "# save off the history\n",
    "history0b = pd.DataFrame(hist0b.history)\n",
    "history0b.to_csv('history_model0b.csv')\n",
    "\n",
    "# predict on test data and format for kaggle submission\n",
    "pred0b = predict_for_kaggle(model0b, test_data, 'kaggle_model0b.csv')\n",
    "\n",
    "# store the results\n",
    "result_dict['CNN Model0b'] = [\n",
    "    round(np.sqrt(hist0b.history['loss'][-1]) * 48,2), \n",
    "    round(np.sqrt(hist0b.history['val_loss'][-1]) * 48,2),\n",
    "    round(np.sum(runtime0b.times),2)\n",
    "]\n",
    "df = pd.DataFrame(result_dict)\n",
    "with open('results.csv','a') as f:\n",
    "    df.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:18:48.084891Z",
     "start_time": "2018-12-10T03:18:47.840307Z"
    }
   },
   "outputs": [],
   "source": [
    "model1 = build_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T22:43:07.523517Z",
     "start_time": "2018-12-09T22:28:17.880139Z"
    }
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "hist1, runtime1 = train_model(\n",
    "    model1, train_data_orig, train_labels_orig, \n",
    "    dev_data_orig, dev_labels_orig, epochs=50\n",
    ")\n",
    "\n",
    "# save off the history\n",
    "history1 = pd.DataFrame(hist1.history)\n",
    "history1.to_csv('history_model1.csv')\n",
    "\n",
    "# predict on test data and format for kaggle submission\n",
    "pred1 = predict_for_kaggle(model1, test_data, 'kaggle_model1.csv')\n",
    "\n",
    "# store the results\n",
    "result_dict['CNN Model1'] = [\n",
    "    round(np.sqrt(hist1.history['loss'][-1]) * 48,2), \n",
    "    round(np.sqrt(hist1.history['val_loss'][-1]) * 48,2),\n",
    "    round(np.sum(runtime1.times),2)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could try running this for longer, but the way the validation loss levels off even as the training loss continues to shrink shows that the model is overfitting. This is unsurprising given the small size of our data set, and the large number of parameters. For better results, we should next try the full (unaugmented) data set and see how it fares."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T20:41:04.607858Z",
     "start_time": "2018-12-09T20:41:04.401323Z"
    }
   },
   "outputs": [],
   "source": [
    "model2 = build_CNN()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T21:09:55.569618Z",
     "start_time": "2018-12-09T20:41:04.610865Z"
    }
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "hist2, runtime2 = train_model(\n",
    "    model2, train_data_aug, train_labels_aug, \n",
    "    dev_data_orig, dev_labels_orig, epochs=50\n",
    ")\n",
    "\n",
    "# save off the history\n",
    "history2 = pd.DataFrame(hist2.history)\n",
    "history2.to_csv('history_model2.csv')\n",
    "\n",
    "# predict on test data and format for kaggle submission\n",
    "pred2 = predict_for_kaggle(model2, test_data, 'kaggle_model2.csv')\n",
    "\n",
    "# store the results\n",
    "result_dict['CNN Model2'] = [\n",
    "    round(np.sqrt(hist2.history['loss'][-1]) * 48,2), \n",
    "    round(np.sqrt(hist2.history['val_loss'][-1]) * 48,2), \n",
    "    round(np.sum(runtime2.times),2)\n",
    "]\n",
    "df = pd.DataFrame(result_dict)\n",
    "with open('results.csv','a') as f:\n",
    "    df.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This did significantly better and the validation loss was still improving alongside the training loss at the end of ten epochs. Given this continued improvement, it would be worth running this for longer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict missing values\n",
    "A large percentage of the points are missing, meaning we are not using a large percentage of the information we have in the dataset. However facial keypoints will, in general, follow location patterns across images of faces. Uing a simple two layer neural net we use the moset commonly labeled key points to predict values for the features that are not labeled in a majority of the data. Then we can fill the missing labels in with these predicted points and retrain the data with no missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the 2-layer NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T22:51:18.245622Z",
     "start_time": "2018-12-09T22:51:18.203509Z"
    }
   },
   "outputs": [],
   "source": [
    "basicNN = Sequential()\n",
    "basicNN.add(Dense(units=1000,activation='relu'))\n",
    "basicNN.add(Dense(units=1000,activation='relu'))\n",
    "basicNN.add(Dense(units=1000,activation='relu'))\n",
    "\n",
    "# create the output layer\n",
    "basicNN.add(Dense(units=30))\n",
    "\n",
    "# compile the model\n",
    "basicNN.compile(loss=mean_squared_error_with_missing, optimizer='Adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T22:51:37.981282Z",
     "start_time": "2018-12-09T22:51:18.247628Z"
    }
   },
   "outputs": [],
   "source": [
    "NN_hist, NN_time = train_model(\n",
    "    basicNN,\n",
    "    train_labels_aug_comp[:,[0,1,2,3,20,21,28,29]], train_labels_aug_comp,\n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T22:51:38.938367Z",
     "start_time": "2018-12-09T22:51:37.983297Z"
    }
   },
   "outputs": [],
   "source": [
    "idx = np.random.randint(0, len(train_data_aug), 16)\n",
    "data_sample = train_data_aug[idx, :, :, :]\n",
    "\n",
    "pred = basicNN.predict(train_labels_aug[:,[0,1,2,3,20,21,28,29]])\n",
    "\n",
    "label_sample = pred[idx, :]\n",
    "label_sample_true = train_labels_aug[idx, :]\n",
    "\n",
    "plot_sample(data_sample, label_sample_true, labels2=label_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T22:51:39.470789Z",
     "start_time": "2018-12-09T22:51:38.938367Z"
    }
   },
   "outputs": [],
   "source": [
    "train_labels_full = train_labels_aug.copy()\n",
    "for i in range(train_labels_full.shape[1]):\n",
    "    for j,v in enumerate(train_labels_full[:,i]):\n",
    "        if np.isnan(v):\n",
    "            train_labels_full[j,i] = pred[j,i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T21:10:15.184248Z",
     "start_time": "2018-12-09T21:10:14.991701Z"
    }
   },
   "outputs": [],
   "source": [
    "# augment some data or change a parameter\n",
    "model3 = build_CNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing against augmented dev data with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T21:39:00.436784Z",
     "start_time": "2018-12-09T21:10:15.744689Z"
    }
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "hist3, runtime3 = train_model(\n",
    "    model3, train_data_aug, train_labels_full, \n",
    "    dev_data_orig, dev_labels_orig, epochs=50\n",
    ")\n",
    "\n",
    "# save off the history\n",
    "history3 = pd.DataFrame(hist3.history)\n",
    "history3.to_csv('history_model3.csv')\n",
    "\n",
    "# predict on test data and format for kaggle submission\n",
    "pred3 = predict_for_kaggle(model3, test_data, 'kaggle_model3.csv')\n",
    "\n",
    "# store the results\n",
    "result_dict['CNN Model3'] = [\n",
    "    round(np.sqrt(hist3.history['loss'][-1]) * 48,2), \n",
    "    round(np.sqrt(hist3.history['val_loss'][-1]) * 48,2), \n",
    "    round(np.sum(runtime3.times),2)\n",
    "]\n",
    "df = pd.DataFrame(result_dict)\n",
    "with open('results.csv','a') as f:\n",
    "    df.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this model, we add dropout layers after each pooling layer. The objective of the dropout layers is to help with generalization and avoid overfitting. The dropout layer randomly selects a percentage of nodes at each layer and throws their information out, prior to backpropagation. The idea is that some of the information you have \"learned\" is too specific too the training set and therefore throwing out a portion of it makes you learn slower, but helps you generalize better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T22:51:39.704822Z",
     "start_time": "2018-12-09T22:51:39.470789Z"
    }
   },
   "outputs": [],
   "source": [
    "# adding droput layers\n",
    "model4 = build_CNN(dropout=[0.1,0.2,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing against augmented dev data with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T23:22:44.336535Z",
     "start_time": "2018-12-09T22:51:40.256608Z"
    }
   },
   "outputs": [],
   "source": [
    "# train the model\n",
    "hist4, runtime4 = train_model(\n",
    "    model4, train_data_aug, train_labels_full, \n",
    "    dev_data_orig, dev_labels_orig, epochs=50\n",
    ")\n",
    "\n",
    "# save off the history\n",
    "history4 = pd.DataFrame(hist4.history)\n",
    "history4.to_csv('history_model4.csv')\n",
    "\n",
    "# predict on test data and format for kaggle submission\n",
    "pred4 = predict_for_kaggle(model4, test_data, 'kaggle_model4.csv')\n",
    "    \n",
    "# store the results\n",
    "result_dict['CNN Model4'] = [\n",
    "    round(np.sqrt(hist4.history['loss'][-1]) * 48,2), \n",
    "    round(np.sqrt(hist4.history['val_loss'][-1]) * 48,2), \n",
    "    round(np.sum(runtime4.times),2)\n",
    "]\n",
    "df = pd.DataFrame(result_dict)\n",
    "with open('results.csv','a') as f:\n",
    "    df.to_csv(f, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize training improvement\n",
    "Doesn't look like an improvement, but it will once we train on the whole data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T23:22:44.365557Z",
     "start_time": "2018-12-09T23:22:44.337482Z"
    }
   },
   "outputs": [],
   "source": [
    "hist0b = pd.read_csv('history_model0b.csv')\n",
    "hist0a = pd.read_csv('history_model0a.csv')\n",
    "hist1 = pd.read_csv('history_model1.csv')\n",
    "hist2 = pd.read_csv('history_model2.csv')\n",
    "hist3 = pd.read_csv('history_model3.csv')\n",
    "hist4 = pd.read_csv('history_model4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-09T23:28:15.925285Z",
     "start_time": "2018-12-09T23:28:15.527062Z"
    }
   },
   "outputs": [],
   "source": [
    "val_rms0a = hist0a['val_loss']\n",
    "train_rms0a = hist0a['loss']\n",
    "val_rms0b = hist0b['val_loss']\n",
    "train_rms0b = hist0b['loss']\n",
    "val_rms1 = hist1['val_loss']\n",
    "train_rms1 = hist1['loss']\n",
    "val_rms2 = hist2['val_loss']\n",
    "train_rms2 = hist2['loss']\n",
    "val_rms3 = hist3['val_loss']\n",
    "train_rms3 = hist3['loss']\n",
    "val_rms4 = hist4['val_loss']\n",
    "train_rms4 = hist4['loss']\n",
    "\n",
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.semilogy(val_rms0a, 'c-')\n",
    "plt.semilogy(train_rms0a, 'c--')\n",
    "plt.semilogy(val_rms0b, 'm-')\n",
    "plt.semilogy(train_rms0b, 'm--')\n",
    "plt.semilogy(val_rms1, 'g-')\n",
    "plt.semilogy(train_rms1, 'g--')\n",
    "plt.semilogy(val_rms2, 'b-')\n",
    "plt.semilogy(train_rms2, 'b--')\n",
    "plt.semilogy(val_rms3, 'r-')\n",
    "plt.semilogy(train_rms3, 'r--')\n",
    "plt.semilogy(val_rms4, 'k-')\n",
    "plt.semilogy(train_rms4, 'k--')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss - Mean Squared Error')\n",
    "\n",
    "plt.legend([\n",
    "    'Complete Data - Val. Loss', 'Complete Data - Train Loss',\n",
    "    'Complete Data + Aug. - Val. Loss', 'Complete Data + Aug. - Train Loss',\n",
    "    'Orig. Data Only - Val. Loss', 'Orig. Data Only - Train Loss',\n",
    "    'Orig. Data + Aug. - Val. Loss', 'Orig. Data + Aug. - Train Loss',\n",
    "    'Orig. Data + Aug. + Pred. NAs - Val. Loss', 'Orig. Data + Aug. + Pred. NAs - Train Loss',\n",
    "    'Add Dropout layers - Val. Loss', 'Add Dropout layers - Train Loss',\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we are comparing the training performance of each of our CNN models. We tried running for longer than 50 epochs, but were limited by our hardware so we decided to cap it at 50 epochs. The dotted lines represent the training loss, and the solid lines represent the test loss. The lowest two lines represent the training loss on the complete data set with no missing values which is also being validated on the complete dev set with no missing values. You can see that we are starting to see pretty severe overfitting by the fact that the loss on the training data continues to trend downward, while the validation loss remains relatively flat. In general our models are converging fairly quickly, most of the time within the first 10 or 20 epochs. This is likely due to using the Adam optimizer which adapts the learning rate rapidly and converges much faster than traditional SGD. One notable exception is the fourth model where we added dropout layers and we can see the training loss converges much slower than the models with no dropout. There are two spikes that we see, the first blue spike we cannot explain, but the last spike in the dropout curve happened because our GPU ran out of memory and the training crashed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize the Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:41:11.976964Z",
     "start_time": "2018-12-10T03:41:09.616271Z"
    }
   },
   "outputs": [],
   "source": [
    "# pull in the predicted data\n",
    "LUT = pd.read_csv('IDLookupTable.csv')\n",
    "p0a = pd.read_csv('kaggle_model0a.csv')\n",
    "p0b = pd.read_csv('kaggle_model0b.csv')\n",
    "p1 = pd.read_csv('kaggle_model1.csv')\n",
    "p2 = pd.read_csv('kaggle_model2.csv')\n",
    "p3 = pd.read_csv('kaggle_model3.csv')\n",
    "p4 = pd.read_csv('kaggle_model4.csv')\n",
    "\n",
    "# reformat the predicted data\n",
    "LUT['p0a'] = p0a.Location\n",
    "LUT['p0b'] = p0b.Location\n",
    "LUT['p1'] = p1.Location\n",
    "LUT['p2'] = p2.Location\n",
    "LUT['p3'] = p3.Location\n",
    "LUT['p4'] = p4.Location\n",
    "\n",
    "cols = {'p0a','p0b','p1','p2','p3','p4'}\n",
    "labels = [\n",
    "    np.array([LUT[col][LUT.ImageId == i+1].values for i in range(6)])\n",
    "    for col in cols\n",
    "]\n",
    "\n",
    "# plot a sample\n",
    "idx = list(range(6))\n",
    "sample_data = test_data[idx]\n",
    "\n",
    "fig, axes = plt.subplots(6,6,figsize=(20,20))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.2)\n",
    "colors = ['c','m','g','b','r','y']\n",
    "titles = ['net 0a', 'net 0b','net 1','net 2','net 3','net 4']\n",
    "for i in range(6):\n",
    "    for j in range(6):\n",
    "        ax = axes[i,j]\n",
    "        img = sample_data[j].reshape(96,96)\n",
    "        labs = labels[i][j]\n",
    "        ax.imshow(img, cmap='gray')\n",
    "        ax.scatter(labs[::2], labs[1::2], c=colors[i])\n",
    "        ax.set_title(titles[i], fontsize=20)\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put a conclusion here comparing and contrasting the models and how well we did on Kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline Models\n",
    "\n",
    "summary = pd.DataFrame.from_dict(result_dict)\n",
    "summary = summary.head(2)\n",
    "\n",
    "kaggle_scores = pd.DataFrame([4.46, 4.08, 4.74, 3.91, 3.96, 46.32, 4.96, 4.11, 4.07], columns=summary.columns.values)\n",
    "\n",
    "summary = summary.append(kaggle_scores, ignore_index=True)\n",
    "\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-12-10T03:31:27.218003Z",
     "start_time": "2018-12-10T03:31:27.198024Z"
    }
   },
   "outputs": [],
   "source": [
    "# CNN Models\n",
    "\n",
    "results = pd.read_csv('results.csv')\n",
    "results.columns.values[0] = 'index'\n",
    "results.set_index(results['index'], inplace=True)\n",
    "results = results.iloc[:,1:]\n",
    "results = results.head(3)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table = pd.concat([results, summary], axis=1)\n",
    "results_table "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - http://deeplearning.net/tutorial/lenet.html#lenet\n",
    " - https://arxiv.org/abs/1206.5533\n",
    " - https://arxiv.org/abs/1412.6980v8\n",
    " - http://danielnouri.org/notes/2014/12/17/using-convolutional-neural-nets-to-detect-facial-keypoints-tutorial/\n",
    " - https://arxiv.org/abs/1710.05279\n",
    " - https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4978658/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix\n",
    "\n",
    "## Erroneous Data Algorithm\n",
    "\n",
    "#### Note: It is not recommended to run this cell because it is out of sequence\n",
    "\n",
    "During our EDA, we incidentally discovered that some data was very clearly mislabeled, so we decided to search for and remove bad data to reduce noise. Since the data set is large, we needed an algorithm to flag likely bad data. Our method of choice was to train our CNN model on the full training data, then use that model to predict values _on the training data_, flagging any image where a single keypoint was off by 40 pixels or more. We threw out 69 images that met this criterion. A few images looked mostly correct and may have been collateral damage. A further improvement attempt could be to only throw out the keypoints that were questionable and keep the ones that looked good. We did want to be wary of throwing out too much, since we were training on the same data we were predicting on, so our predictions were only so reliable. Another possible improvement could be to incorporate cross-validation within the training set for this error identification exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = build_CNN()\n",
    "\n",
    "time_callback = TimeHistory()\n",
    "hist = keras.callbacks.History()\n",
    "\n",
    "model1.fit(\n",
    "    train_data_raw, train_labels_raw, \n",
    "    batch_size=32,\n",
    "    epochs=1, \n",
    "    verbose=1,\n",
    "    callbacks=[hist, time_callback]\n",
    ")\n",
    "predictions = model1.predict(train_data_raw, verbose=1)\n",
    "\n",
    "# get array of squared errors\n",
    "error = predictions*96 - train_labels_raw*96\n",
    "sq_err = error ** 2\n",
    "\n",
    "# flag any images where a single keypoint dimension is off by a threshold distance\n",
    "flagged = []\n",
    "for i in range(sq_err.shape[0]):\n",
    "    threshold = 40\n",
    "    if np.any(sq_err[i] > threshold ** 2):\n",
    "        flagged.append(i)\n",
    "print(flagged)\n",
    "\n",
    "# plot these images as a sanity check that they are in face \"bad\" data\n",
    "i = 0\n",
    "rows = 8\n",
    "cols = len(flagged)//rows + 1\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "fig.subplots_adjust(left=0, right=1, bottom=0, top=1, hspace=0.05, wspace=0.05)\n",
    "for index in flagged:\n",
    "    ax = fig.add_subplot(rows, cols, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(train_data_raw[index].reshape(96,96), cmap='gray')\n",
    "    ax.scatter(train_labels_raw[index][0::2] * 48 + 48, train_labels_raw[i][1::2] * 48 + 48, c='r')\n",
    "    i += 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3virtualenv",
   "language": "python",
   "name": "py3virtualenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
