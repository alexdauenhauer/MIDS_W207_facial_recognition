{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# W207 Final Project: Facial Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the final project submission from Team MapReduce,MapReuse,MapRecycle for W207: Applied Machine Learning as part of the MIDS program at UC Berkeley. We are working with data from https://www.kaggle.com/c/facial-keypoints-detection/data and the goal is to accurately identify facial features on an (x, y) coordinate system based on an input image. \n",
    "\n",
    "## Communicate on SLACK when working on main notebook as much as possible\n",
    "\n",
    "*Data Observations*\n",
    "- There are half face images, etc\n",
    "\n",
    "*Ideas to try*\n",
    "- Use other features to predict one specific feature\n",
    "\n",
    "- Break out the image into its own matrix where each pixel is a feature and then predict each facial characteristic position\n",
    "    - First use subset of images that contain all key points and then just predict the locations. \n",
    "\n",
    "*Feature Improvement Ideas*\n",
    "- Rotating the images a bit\n",
    "- Blurring the images a bit\n",
    "- Maybe normally the pixel values by average pixel shade of every picture\n",
    "- Seperate the image into different quadrants \n",
    "- Compressing 256 base image to 16 base image. Just black and white? Interval of -1 to 1?\n",
    "\n",
    "*Knockout List/Plan*\n",
    "- Print first 10-20 images generally. \n",
    "- Print edge cases for different facial feature locations.\n",
    "\n",
    "- Very basic test with a couple different basic algorithms. \n",
    "- Start with very basic one hidden layer perception\n",
    "- Improve neural network to be CNN architecture. \n",
    "- Prepare a summary table of quality metrics: L2 distance, L1 distance\n",
    "\n",
    "*Naming/Working Rules*\n",
    "- train_data, train_labels\n",
    "- dev_data, dev_labels\n",
    "\n",
    "- Feature Engineering: put \"_transformation done\". Ex: train_data_blur\n",
    "\n",
    "*Useful Items*\n",
    "- Learn Keras\n",
    "- https://www.kaggle.com/c/facial-keypoints-detection#getting-started-with-r\n",
    "- http://adventuresinmachinelearning.com/keras-tutorial-cnn-11-lines/\n",
    "- https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm#k-NN_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name np_utils",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mImportError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-2455c58de31e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Maddie\\AppData\\Local\\conda\\conda\\envs\\py27\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Maddie\\AppData\\Local\\conda\\conda\\envs\\py27\\lib\\site-packages\\keras\\utils\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgeneric_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdata_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mio_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name np_utils"
     ]
    }
   ],
   "source": [
    "# Import a bunch of libraries.\n",
    "import time\n",
    "import os\n",
    "# os.environ[\"MKL_THREADING_LAYER\"] = \"GNU\"\n",
    "import keras\n",
    "import theano\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import decimal\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from scipy import stats\n",
    "\n",
    "# Set the randomizer seed so results are the same each time.\n",
    "np.random.seed(0)\n",
    "\n",
    "print 'theano version:', theano.__version__\n",
    "print 'theano config device:', theano.config.device, theano.config.floatX\n",
    "print 'keras version:', keras.__version__\n",
    "print 'pandas version:', pd.__version__\n",
    "print 'numpy version:', np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns available:\n",
      "['left_eye_center_x' 'left_eye_center_y' 'right_eye_center_x'\n",
      " 'right_eye_center_y' 'left_eye_inner_corner_x' 'left_eye_inner_corner_y'\n",
      " 'left_eye_outer_corner_x' 'left_eye_outer_corner_y'\n",
      " 'right_eye_inner_corner_x' 'right_eye_inner_corner_y'\n",
      " 'right_eye_outer_corner_x' 'right_eye_outer_corner_y'\n",
      " 'left_eyebrow_inner_end_x' 'left_eyebrow_inner_end_y'\n",
      " 'left_eyebrow_outer_end_x' 'left_eyebrow_outer_end_y'\n",
      " 'right_eyebrow_inner_end_x' 'right_eyebrow_inner_end_y'\n",
      " 'right_eyebrow_outer_end_x' 'right_eyebrow_outer_end_y' 'nose_tip_x'\n",
      " 'nose_tip_y' 'mouth_left_corner_x' 'mouth_left_corner_y'\n",
      " 'mouth_right_corner_x' 'mouth_right_corner_y' 'mouth_center_top_lip_x'\n",
      " 'mouth_center_top_lip_y' 'mouth_center_bottom_lip_x'\n",
      " 'mouth_center_bottom_lip_y' 'Image']\n",
      "\n",
      "Train data shape (5639L,)\n",
      "Dev data shape (1410L,)\n",
      "Train labels shape (5639, 30)\n",
      "Dev labels shape (1410, 30)\n",
      "\n",
      "Data Generation Finished\n"
     ]
    }
   ],
   "source": [
    "# Load the data from downloaded file and split the train into a smaller train and dev\n",
    "\n",
    "train = pd.read_csv('training.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print \"Columns available:\"\n",
    "print train.columns.values \n",
    "\n",
    "def process_datasets(data):\n",
    "    facial_point_labels = data.iloc[:, :-1]\n",
    "    images_pixel_feature = data.Image.apply(lambda im: np.fromstring(im, sep=' '))\n",
    "    \n",
    "    # Turn below on to the regressions below.\n",
    "    #images_pixel_feature = pd.DataFrame(images_pixel_feature.values.tolist())\n",
    "    \n",
    "    # Filling NAs with 0 \n",
    "    facial_point_labels = facial_point_labels.fillna(0)\n",
    "    images_pixel_feature = images_pixel_feature.fillna(0)\n",
    "    \n",
    "    return images_pixel_feature, facial_point_labels\n",
    "\n",
    "train_all_features, train_all_labels = process_datasets(train)\n",
    "\n",
    "percent_to_dev = 0.2 # 20% of the data will go to dev\n",
    "\n",
    "train_data, dev_data, train_labels, dev_labels = train_test_split(train_all_features, train_all_labels, test_size=percent_to_dev)\n",
    "test_data, test_labels = process_datasets(test)\n",
    "\n",
    "print \"\\nTrain data shape\", train_data.shape\n",
    "print \"Dev data shape\", dev_data.shape\n",
    "print \"Train labels shape\", train_labels.shape\n",
    "print \"Dev labels shape\", dev_labels.shape\n",
    "\n",
    "print \"\\nData Generation Finished\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>left_eye_center_x</th>\n",
       "      <th>left_eye_center_y</th>\n",
       "      <th>right_eye_center_x</th>\n",
       "      <th>right_eye_center_y</th>\n",
       "      <th>left_eye_inner_corner_x</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>69.009155</td>\n",
       "      <td>37.392891</td>\n",
       "      <td>31.856165</td>\n",
       "      <td>35.623621</td>\n",
       "      <td>63.259052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>66.104842</td>\n",
       "      <td>34.633263</td>\n",
       "      <td>29.693684</td>\n",
       "      <td>35.197895</td>\n",
       "      <td>59.330526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4236</th>\n",
       "      <td>67.640071</td>\n",
       "      <td>35.673855</td>\n",
       "      <td>31.773689</td>\n",
       "      <td>36.314336</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>66.902495</td>\n",
       "      <td>37.388198</td>\n",
       "      <td>30.371168</td>\n",
       "      <td>39.087303</td>\n",
       "      <td>60.956198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2821</th>\n",
       "      <td>68.292978</td>\n",
       "      <td>37.460391</td>\n",
       "      <td>29.048711</td>\n",
       "      <td>38.626062</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      left_eye_center_x  left_eye_center_y  right_eye_center_x  \\\n",
       "448           69.009155          37.392891           31.856165   \n",
       "686           66.104842          34.633263           29.693684   \n",
       "4236          67.640071          35.673855           31.773689   \n",
       "204           66.902495          37.388198           30.371168   \n",
       "2821          68.292978          37.460391           29.048711   \n",
       "\n",
       "      right_eye_center_y  left_eye_inner_corner_x  \n",
       "448            35.623621                63.259052  \n",
       "686            35.197895                59.330526  \n",
       "4236           36.314336                 0.000000  \n",
       "204            39.087303                60.956198  \n",
       "2821           38.626062                 0.000000  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print first couple labels\n",
    "train_labels.iloc[:5,:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EDA: Print a few faces (Mark)\n",
    "\n",
    "for example in range(2,5):\n",
    "    img = train_data[example].reshape(96,96)\n",
    "    img.shape\n",
    "    \n",
    "    plt.figure()\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    for c in range(0, len(train_labels.columns)-1, 2):\n",
    "        x = train_labels[train_labels.columns[c]][example]\n",
    "        y = train_labels[train_labels.columns[c+1]][example]\n",
    "        plt.scatter(x,y,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EDA: Print interesting edge cases images (Mark)\n",
    "\n",
    "# NOTES: Currently having plotting issues. See issue #2 on GitHub for more information.\n",
    "\n",
    "interesting_cases = []\n",
    "\n",
    "# additional interesting cases to explore if time allows:\n",
    "# - multiple faces in one image\n",
    "# - upside down faces\n",
    "# - incomplete faces (not all key points present)\n",
    "# - race/lighting (average shade of pixels in facial region, plot couple darkest/lightest)\n",
    "# - faces halfway offscreen/covered (one eye present, one not)\n",
    "\n",
    "# compile interesting cases\n",
    "interesting_cases.extend(train_labels.nose_tip_x.nsmallest(2).keys())          # noses near left of screen\n",
    "interesting_cases.extend(train_labels.nose_tip_x.nlargest(2).keys())           # noses near right of screen\n",
    "interesting_cases.extend(train_labels.nose_tip_y.nsmallest(2).keys())          # noses near top of screen\n",
    "interesting_cases.extend((train_labels.right_eye_center_x -\n",
    "                          train_labels.left_eye_center_x).nsmallest(2).keys()) # small faces\n",
    "interesting_cases.extend((train_labels.right_eye_center_x -\n",
    "                          train_labels.left_eye_center_x).nlargest(2).keys())  # wide faces\n",
    "\n",
    "# plot these cases with key points\n",
    "for index in interesting_cases:\n",
    "    train_data_square = train_data[index].reshape(96,96)\n",
    "    plt.figure()\n",
    "    plt.imshow(train_data_square, cmap='gray')\n",
    "    for c in range(0, len(train_labels.columns)-1, 2):\n",
    "        x = train_labels[train_labels.columns[c]][index]\n",
    "        y = train_labels[train_labels.columns[c+1]][index]\n",
    "        plt.scatter(x,y,c='r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Algorithms to try:\n",
    "# Need to activate transformation above to change list of items to actual columns to get it working. Is this right way to do it?\n",
    "\n",
    "regressors = {\n",
    "    'LinearRegression': LinearRegression(),\n",
    "    'DecisionTree': DecisionTreeRegressor(),\n",
    "    'NearestNeighbors': KNeighborsRegressor()\n",
    "} \n",
    "\n",
    "def model_training(model):\n",
    "    \n",
    "    X = train_data\n",
    "    Y = train_labels['left_eye_center_x']\n",
    "        \n",
    "    model.fit(X,Y)\n",
    "    predictions = model.predict(dev_data)\n",
    "    \n",
    "    mse = mean_squared_error(dev_labels['left_eye_center_x'], predictions)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "for k,v in regressors.items():\n",
    "    print k,':',model_training(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Try Simple Single Hidden Layer (800 node) Neural Net Model (Madeline, Alex):\n",
    "\n",
    "\"\"\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build more complex CNN model (Madeline, Alex)\n",
    "\n",
    "### PSEUDOCODE ###\n",
    "def build_model():\n",
    "    \n",
    "    # start with the keras Sequential model which is just a stack of \n",
    "    # layers\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    # add a 2D convolutional layer\n",
    "    model.add_convolutional_2D_layer()\n",
    "    \n",
    "    # add a 2D pooling layer\n",
    "    model.add_Pooling_Layer()\n",
    "    \n",
    "    # add another 2D convolutional layer\n",
    "    model.model.add_convolutional_2D_layer()\n",
    "    \n",
    "    # add another pooling layer\n",
    "    model.add_Pooling_Layer()\n",
    "    \n",
    "    # add output layer using softmax activation\n",
    "    model.add_output_layer()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train the model\n",
    "\n",
    "### PSEUDOCODE ###\n",
    "\n",
    "model.compile()\n",
    "model.fit(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions on the test data\n",
    "\n",
    "### PSEUDOCODE ###\n",
    "pred = model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print out some examples of the predictions\n",
    "\n",
    "### PSEUDOCODE ###\n",
    "fig = plt.figure(figsize=12,8)\n",
    "idx = np.random.randint(0, len(test_data), size=16)\n",
    "for i in idx:\n",
    "    img = test_data[i].reshape(96, 96)\n",
    "    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n",
    "    ax.imshow(img, cmap='gray')\n",
    "    for c in range(0, len(pred.columns)-1, 2):\n",
    "        x_pred = pred[pred.columns[c]][0]\n",
    "        y_pred = pred[pred.columns[c+1]][0]\n",
    "        ax.scatter(x_pred, y_pred, c='r')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
